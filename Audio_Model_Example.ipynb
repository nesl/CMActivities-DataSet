{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "# random seed.\n",
    "rand_seed = 1\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(rand_seed)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(rand_seed)\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, LSTM, Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.core import Permute, Reshape\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(y_data):\n",
    "    Mapping=dict()\n",
    "    sub_dirs=['downstair','upstair','run','jump','walk','handwashing','exercise']\n",
    "\n",
    "    categories=10\n",
    "    count=0\n",
    "    for i in sub_dirs:\n",
    "        Mapping[i]=count\n",
    "        count=count+1\n",
    "\n",
    "    y_features2=[]\n",
    "    for i in range(len(y_data)):\n",
    "        Type=y_data[i]\n",
    "        lab=Mapping[Type]\n",
    "        y_features2.append(lab)\n",
    "\n",
    "    y_features=np.array(y_features2)\n",
    "    y_features=y_features.reshape(y_features.shape[0],1)\n",
    "    from keras.utils import to_categorical\n",
    "    y_features = to_categorical(y_features)\n",
    "\n",
    "    return y_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='ADD_PATH_To_Data'\n",
    "\n",
    "\n",
    "def get_train_data(path=path):\n",
    "    Train_data=np.load(path+'train_5000.npz')\n",
    "    Features_imu=Train_data['arr_0']\n",
    "    Labels=Train_data['arr_1']\n",
    "    Features_sound=Train_data['arr_2']\n",
    "\n",
    "    Labels = one_hot_encoding(Labels)\n",
    "    Features_imu = Features_imu.reshape(Features_imu.shape[0],1, Features_imu.shape[1], Features_imu.shape[2]) \n",
    "\n",
    "    return Features_imu,Labels,Features_sound\n",
    "\n",
    "def get_valid_data(path=path):\n",
    "    Train_data=np.load(path+'valid_1000.npz')\n",
    "    Features_imu=Train_data['arr_0']\n",
    "    Labels=Train_data['arr_1']\n",
    "    Features_sound=Train_data['arr_2']\n",
    "\n",
    "    Labels = one_hot_encoding(Labels)\n",
    "    Features_imu = Features_imu.reshape(Features_imu.shape[0],1, Features_imu.shape[1], Features_imu.shape[2]) \n",
    "\n",
    "    return Features_imu,Labels,Features_sound\n",
    "\n",
    "def get_test_data(path=path):\n",
    "    Train_data=np.load(path+'test_1377.npz')\n",
    "    Features_imu=Train_data['arr_0']\n",
    "    Labels=Train_data['arr_1']\n",
    "    Features_sound=Train_data['arr_2']\n",
    "\n",
    "    Labels = one_hot_encoding(Labels)\n",
    "    Features_imu = Features_imu.reshape(Features_imu.shape[0],1, Features_imu.shape[1], Features_imu.shape[2]) \n",
    "\n",
    "    return Features_imu,Labels,Features_sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1, 40, 12) (5000, 7) (5000, 193)\n",
      "Train Classes distribution:  [760. 994. 546. 780. 532. 732. 656.]\n",
      "(1000, 1, 40, 12) (1000, 7) (1000, 193)\n",
      "Valid Classes distribution:  [150. 188. 136. 141.  98. 157. 130.]\n",
      "(1377, 1, 40, 12) (1377, 7) (1377, 193)\n",
      "Test Classes distribution:  [219. 268. 124. 146. 143. 234. 243.]\n"
     ]
    }
   ],
   "source": [
    "Features_imu,Labels,Features_sound = get_train_data()\n",
    "print(Features_imu.shape, Labels.shape, Features_sound.shape)\n",
    "print('Train Classes distribution: ',np.sum(Labels, axis =0))\n",
    "\n",
    "Features_imu2,Labels2,Features_sound2 = get_valid_data()\n",
    "print(Features_imu2.shape, Labels2.shape, Features_sound2.shape)\n",
    "print('Valid Classes distribution: ',np.sum(Labels2, axis =0))\n",
    "\n",
    "Features_imu3,Labels3,Features_sound3 = get_test_data()\n",
    "print(Features_imu3.shape, Labels3.shape, Features_sound3.shape)\n",
    "print('Test Classes distribution: ',np.sum(Labels3, axis =0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, \n",
    "                       decay=0.0, amsgrad=False)\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "\n",
    "def build_scrath_sound_model_layers_diff():\n",
    "    \n",
    "    print('building the model ... ')\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=(193,), activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax', name = 'OUTPUT'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer= adam,\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building the model ... \n"
     ]
    }
   ],
   "source": [
    "sound_model = build_scrath_sound_model_layers_diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               49664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "OUTPUT (Dense)               (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 157,063\n",
      "Trainable params: 157,063\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sound_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/nesl/Sandeep/Trained_models/Audio_Example'\n",
    "\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=model_path, verbose=1,monitor='val_acc' ,save_best_only=True, save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 1000 samples\n",
      "Epoch 1/500\n",
      "5000/5000 [==============================] - 1s 247us/step - loss: 5.5469 - acc: 0.2430 - val_loss: 1.3679 - val_acc: 0.4460\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.44600, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 2/500\n",
      "5000/5000 [==============================] - 0s 40us/step - loss: 1.2563 - acc: 0.4698 - val_loss: 0.9794 - val_acc: 0.5740\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.44600 to 0.57400, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 3/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.9638 - acc: 0.6010 - val_loss: 0.7552 - val_acc: 0.7060\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.57400 to 0.70600, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 4/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.8188 - acc: 0.6486 - val_loss: 0.6836 - val_acc: 0.7290\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.70600 to 0.72900, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 5/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.7352 - acc: 0.6756 - val_loss: 0.6168 - val_acc: 0.7340\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.72900 to 0.73400, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 6/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.6156 - acc: 0.7116 - val_loss: 0.5139 - val_acc: 0.7590\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.73400 to 0.75900, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 7/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.5504 - acc: 0.7464 - val_loss: 0.4418 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.75900 to 0.81200, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 8/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.5374 - acc: 0.7532 - val_loss: 0.4868 - val_acc: 0.7800\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.81200\n",
      "Epoch 9/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.5177 - acc: 0.7562 - val_loss: 0.5452 - val_acc: 0.7560\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.81200\n",
      "Epoch 10/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.5630 - acc: 0.7494 - val_loss: 0.5058 - val_acc: 0.7750\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.81200\n",
      "Epoch 11/500\n",
      "5000/5000 [==============================] - 0s 41us/step - loss: 0.5107 - acc: 0.7550 - val_loss: 0.4364 - val_acc: 0.7850\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.81200\n",
      "Epoch 12/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.5042 - acc: 0.7594 - val_loss: 0.4307 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.81200\n",
      "Epoch 13/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.5007 - acc: 0.7618 - val_loss: 0.4130 - val_acc: 0.8110\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.81200\n",
      "Epoch 14/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.4859 - acc: 0.7754 - val_loss: 0.4368 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.81200\n",
      "Epoch 15/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.4374 - acc: 0.7964 - val_loss: 0.3897 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.81200\n",
      "Epoch 16/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.5131 - acc: 0.7676 - val_loss: 0.4354 - val_acc: 0.8030\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.81200\n",
      "Epoch 17/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.4430 - acc: 0.7900 - val_loss: 0.3712 - val_acc: 0.8360\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.81200 to 0.83600, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 18/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.4109 - acc: 0.8060 - val_loss: 0.4116 - val_acc: 0.8320\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.83600\n",
      "Epoch 19/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.4374 - acc: 0.7994 - val_loss: 0.3548 - val_acc: 0.8370\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.83600 to 0.83700, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 20/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.4068 - acc: 0.8078 - val_loss: 0.3957 - val_acc: 0.8300\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.83700\n",
      "Epoch 21/500\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.3963 - acc: 0.8128 - val_loss: 0.3161 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.83700 to 0.85800, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 22/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.3696 - acc: 0.8250 - val_loss: 0.3462 - val_acc: 0.8450\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.85800\n",
      "Epoch 23/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.4101 - acc: 0.8052 - val_loss: 0.6308 - val_acc: 0.7750\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.85800\n",
      "Epoch 24/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.5514 - acc: 0.7516 - val_loss: 0.3961 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.85800\n",
      "Epoch 25/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.3889 - acc: 0.8192 - val_loss: 0.3565 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.85800\n",
      "Epoch 26/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.3720 - acc: 0.8306 - val_loss: 0.3389 - val_acc: 0.8300\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.85800\n",
      "Epoch 27/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.3615 - acc: 0.8252 - val_loss: 0.4177 - val_acc: 0.8360\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.85800\n",
      "Epoch 28/500\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.3765 - acc: 0.8204 - val_loss: 0.3377 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.85800 to 0.87300, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 29/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.3830 - acc: 0.8248 - val_loss: 0.3245 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.87300\n",
      "Epoch 30/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.3673 - acc: 0.8324 - val_loss: 0.2926 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.87300 to 0.89000, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 31/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.3264 - acc: 0.8488 - val_loss: 0.3069 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.89000\n",
      "Epoch 32/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.3512 - acc: 0.8446 - val_loss: 0.4642 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.89000\n",
      "Epoch 33/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.3457 - acc: 0.8452 - val_loss: 0.3108 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.89000\n",
      "Epoch 34/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.3492 - acc: 0.8456 - val_loss: 0.2870 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.89000\n",
      "Epoch 35/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.3168 - acc: 0.8528 - val_loss: 0.2730 - val_acc: 0.8820\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.89000\n",
      "Epoch 36/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.3073 - acc: 0.8560 - val_loss: 0.3028 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.89000\n",
      "Epoch 37/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.3085 - acc: 0.8558 - val_loss: 0.2645 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.89000\n",
      "Epoch 38/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.3128 - acc: 0.8518 - val_loss: 0.3230 - val_acc: 0.8760\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.89000\n",
      "Epoch 39/500\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.3185 - acc: 0.8532 - val_loss: 0.2744 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.89000\n",
      "Epoch 40/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.2811 - acc: 0.8702 - val_loss: 0.2656 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.89000\n",
      "Epoch 41/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.3441 - acc: 0.8358 - val_loss: 0.3527 - val_acc: 0.8480\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.89000\n",
      "Epoch 42/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.3570 - acc: 0.8450 - val_loss: 0.2871 - val_acc: 0.8790\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.89000\n",
      "Epoch 43/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.3164 - acc: 0.8568 - val_loss: 0.2498 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.89000 to 0.89400, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 44/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.2716 - acc: 0.8746 - val_loss: 0.2251 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.89400 to 0.91500, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 45/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.2414 - acc: 0.8902 - val_loss: 0.2084 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.91500 to 0.92800, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 46/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.2414 - acc: 0.8926 - val_loss: 0.2452 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.92800\n",
      "Epoch 47/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.2290 - acc: 0.9008 - val_loss: 0.2071 - val_acc: 0.9160\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.92800\n",
      "Epoch 48/500\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.2377 - acc: 0.8902 - val_loss: 0.2357 - val_acc: 0.9080\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.92800\n",
      "Epoch 49/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.2290 - acc: 0.8990 - val_loss: 0.2064 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.92800\n",
      "Epoch 50/500\n",
      "5000/5000 [==============================] - 0s 40us/step - loss: 0.2246 - acc: 0.9028 - val_loss: 0.1995 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.92800\n",
      "Epoch 51/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.2087 - acc: 0.9064 - val_loss: 0.2078 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.92800\n",
      "Epoch 52/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.2000 - acc: 0.9162 - val_loss: 0.1895 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.92800 to 0.93400, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 53/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.1958 - acc: 0.9130 - val_loss: 0.1841 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.93400 to 0.93800, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 54/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.1947 - acc: 0.9170 - val_loss: 0.2157 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.93800\n",
      "Epoch 55/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.2827 - acc: 0.8864 - val_loss: 0.2314 - val_acc: 0.9030\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.93800\n",
      "Epoch 56/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.2303 - acc: 0.9070 - val_loss: 0.1744 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.93800 to 0.94300, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 57/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.1830 - acc: 0.9270 - val_loss: 0.1632 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.94300 to 0.94400, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 58/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.1827 - acc: 0.9232 - val_loss: 0.1668 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.94400 to 0.95000, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 59/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.1866 - acc: 0.9238 - val_loss: 0.1728 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.95000\n",
      "Epoch 60/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.1776 - acc: 0.9264 - val_loss: 0.1631 - val_acc: 0.9400\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.95000\n",
      "Epoch 61/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.1821 - acc: 0.9236 - val_loss: 0.1574 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.95000\n",
      "Epoch 62/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.1738 - acc: 0.9318 - val_loss: 0.1449 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.95000 to 0.95000, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 63/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.1520 - acc: 0.9358 - val_loss: 0.1474 - val_acc: 0.9480\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.95000\n",
      "Epoch 64/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.1559 - acc: 0.9338 - val_loss: 0.1678 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.95000\n",
      "Epoch 65/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.1583 - acc: 0.9308 - val_loss: 0.1358 - val_acc: 0.9480\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.95000\n",
      "Epoch 66/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.1443 - acc: 0.9394 - val_loss: 0.1473 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.95000\n",
      "Epoch 67/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.1559 - acc: 0.9372 - val_loss: 0.1466 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.95000\n",
      "Epoch 68/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.1315 - acc: 0.9496 - val_loss: 0.1177 - val_acc: 0.9580\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.95000 to 0.95800, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 69/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.1370 - acc: 0.9440 - val_loss: 0.1106 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.95800 to 0.96500, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 70/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.1380 - acc: 0.9462 - val_loss: 0.2311 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.96500\n",
      "Epoch 71/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.1836 - acc: 0.9282 - val_loss: 0.1334 - val_acc: 0.9530\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.96500\n",
      "Epoch 72/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.1489 - acc: 0.9392 - val_loss: 0.1117 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.96500\n",
      "Epoch 73/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.1266 - acc: 0.9496 - val_loss: 0.1047 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.96500\n",
      "Epoch 74/500\n",
      "5000/5000 [==============================] - 0s 42us/step - loss: 0.1195 - acc: 0.9534 - val_loss: 0.1404 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.96500\n",
      "Epoch 75/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.1566 - acc: 0.9356 - val_loss: 0.1430 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.96500\n",
      "Epoch 76/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.1132 - acc: 0.9540 - val_loss: 0.1256 - val_acc: 0.9530\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.96500\n",
      "Epoch 77/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.1109 - acc: 0.9576 - val_loss: 0.1050 - val_acc: 0.9680\n",
      "\n",
      "Epoch 00077: val_acc improved from 0.96500 to 0.96800, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 78/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.1065 - acc: 0.9596 - val_loss: 0.1118 - val_acc: 0.9570\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.96800\n",
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.1125 - acc: 0.9568 - val_loss: 0.1066 - val_acc: 0.9660\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.96800\n",
      "Epoch 80/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.1010 - acc: 0.9608 - val_loss: 0.1423 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.96800\n",
      "Epoch 81/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.1114 - acc: 0.9584 - val_loss: 0.0977 - val_acc: 0.9670\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.96800\n",
      "Epoch 82/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.1032 - acc: 0.9592 - val_loss: 0.1106 - val_acc: 0.9570\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.96800\n",
      "Epoch 83/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.1106 - acc: 0.9572 - val_loss: 0.1304 - val_acc: 0.9580\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.96800\n",
      "Epoch 84/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0933 - acc: 0.9636 - val_loss: 0.1300 - val_acc: 0.9580\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.96800\n",
      "Epoch 85/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.1114 - acc: 0.9548 - val_loss: 0.1331 - val_acc: 0.9520\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.96800\n",
      "Epoch 86/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.1339 - acc: 0.9494 - val_loss: 0.1113 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.96800\n",
      "Epoch 87/500\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.0967 - acc: 0.9630 - val_loss: 0.1078 - val_acc: 0.9690\n",
      "\n",
      "Epoch 00087: val_acc improved from 0.96800 to 0.96900, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 88/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0924 - acc: 0.9640 - val_loss: 0.1267 - val_acc: 0.9590\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.96900\n",
      "Epoch 89/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.1711 - acc: 0.9384 - val_loss: 0.1565 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.96900\n",
      "Epoch 90/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.1276 - acc: 0.9472 - val_loss: 0.1292 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.96900\n",
      "Epoch 91/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.1040 - acc: 0.9598 - val_loss: 0.1239 - val_acc: 0.9600\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.96900\n",
      "Epoch 92/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0932 - acc: 0.9652 - val_loss: 0.1137 - val_acc: 0.9580\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.96900\n",
      "Epoch 93/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0844 - acc: 0.9688 - val_loss: 0.0933 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.96900 to 0.97900, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 94/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0734 - acc: 0.9730 - val_loss: 0.0935 - val_acc: 0.9680\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.97900\n",
      "Epoch 95/500\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.0681 - acc: 0.9750 - val_loss: 0.0840 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00095: val_acc improved from 0.97900 to 0.98400, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 96/500\n",
      "5000/5000 [==============================] - 0s 42us/step - loss: 0.0704 - acc: 0.9750 - val_loss: 0.0930 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.98400\n",
      "Epoch 97/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0644 - acc: 0.9744 - val_loss: 0.0970 - val_acc: 0.9690\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.98400\n",
      "Epoch 98/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.1201 - acc: 0.9536 - val_loss: 0.0820 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.98400\n",
      "Epoch 99/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0681 - acc: 0.9722 - val_loss: 0.1151 - val_acc: 0.9580\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.98400\n",
      "Epoch 100/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0651 - acc: 0.9754 - val_loss: 0.0876 - val_acc: 0.9760\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.98400\n",
      "Epoch 101/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0559 - acc: 0.9796 - val_loss: 0.0884 - val_acc: 0.9760\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.98400\n",
      "Epoch 102/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0507 - acc: 0.9830 - val_loss: 0.0982 - val_acc: 0.9710\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.98400\n",
      "Epoch 103/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0580 - acc: 0.9802 - val_loss: 0.1103 - val_acc: 0.9670\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.98400\n",
      "Epoch 104/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0664 - acc: 0.9768 - val_loss: 0.1472 - val_acc: 0.9570\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.98400\n",
      "Epoch 105/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0642 - acc: 0.9744 - val_loss: 0.0802 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.98400\n",
      "Epoch 106/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0642 - acc: 0.9756 - val_loss: 0.1065 - val_acc: 0.9690\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.98400\n",
      "Epoch 107/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0539 - acc: 0.9806 - val_loss: 0.0881 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.98400\n",
      "Epoch 108/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0576 - acc: 0.9776 - val_loss: 0.1078 - val_acc: 0.9710\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.98400\n",
      "Epoch 109/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0910 - acc: 0.9644 - val_loss: 0.0721 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.98400\n",
      "Epoch 110/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0615 - acc: 0.9778 - val_loss: 0.0832 - val_acc: 0.9710\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.98400\n",
      "Epoch 111/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0694 - acc: 0.9756 - val_loss: 0.0618 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.98400\n",
      "Epoch 112/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0424 - acc: 0.9848 - val_loss: 0.0617 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.98400\n",
      "Epoch 113/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0379 - acc: 0.9880 - val_loss: 0.0914 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.98400\n",
      "Epoch 114/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.1081 - acc: 0.9630 - val_loss: 0.0940 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.98400\n",
      "Epoch 115/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0534 - acc: 0.9818 - val_loss: 0.0718 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.98400\n",
      "Epoch 116/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0380 - acc: 0.9882 - val_loss: 0.0525 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00116: val_acc improved from 0.98400 to 0.98500, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 117/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0410 - acc: 0.9852 - val_loss: 0.0779 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.98500\n",
      "Epoch 118/500\n",
      "5000/5000 [==============================] - 0s 41us/step - loss: 0.0361 - acc: 0.9862 - val_loss: 0.0651 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.98500\n",
      "Epoch 119/500\n",
      "5000/5000 [==============================] - 0s 40us/step - loss: 0.0315 - acc: 0.9882 - val_loss: 0.0690 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.98500\n",
      "Epoch 120/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0611 - acc: 0.9778 - val_loss: 0.0602 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.98500\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 41us/step - loss: 0.0536 - acc: 0.9810 - val_loss: 0.1038 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.98500\n",
      "Epoch 122/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0492 - acc: 0.9846 - val_loss: 0.0889 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.98500\n",
      "Epoch 123/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0445 - acc: 0.9832 - val_loss: 0.0526 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00123: val_acc improved from 0.98500 to 0.98600, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 124/500\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.0372 - acc: 0.9868 - val_loss: 0.0519 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.98600\n",
      "Epoch 125/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0369 - acc: 0.9886 - val_loss: 0.0798 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.98600\n",
      "Epoch 126/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0353 - acc: 0.9886 - val_loss: 0.0627 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.98600\n",
      "Epoch 127/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0467 - acc: 0.9840 - val_loss: 0.0649 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.98600\n",
      "Epoch 128/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0512 - acc: 0.9800 - val_loss: 0.0553 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.98600\n",
      "Epoch 129/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0366 - acc: 0.9864 - val_loss: 0.0674 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.98600\n",
      "Epoch 130/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0454 - acc: 0.9844 - val_loss: 0.1033 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.98600\n",
      "Epoch 131/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.1216 - acc: 0.9600 - val_loss: 0.0841 - val_acc: 0.9710\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.98600\n",
      "Epoch 132/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0550 - acc: 0.9814 - val_loss: 0.0549 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.98600\n",
      "Epoch 133/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0292 - acc: 0.9900 - val_loss: 0.0585 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.98600\n",
      "Epoch 134/500\n",
      "5000/5000 [==============================] - 0s 41us/step - loss: 0.0395 - acc: 0.9860 - val_loss: 0.0592 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.98600\n",
      "Epoch 135/500\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.0221 - acc: 0.9922 - val_loss: 0.0947 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.98600\n",
      "Epoch 136/500\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.0234 - acc: 0.9922 - val_loss: 0.0880 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.98600\n",
      "Epoch 137/500\n",
      "5000/5000 [==============================] - 0s 42us/step - loss: 0.0367 - acc: 0.9884 - val_loss: 0.1037 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.98600\n",
      "Epoch 138/500\n",
      "5000/5000 [==============================] - 0s 41us/step - loss: 0.0796 - acc: 0.9712 - val_loss: 0.0988 - val_acc: 0.9690\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.98600\n",
      "Epoch 139/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0416 - acc: 0.9846 - val_loss: 0.0578 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.98600\n",
      "Epoch 140/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0337 - acc: 0.9876 - val_loss: 0.0616 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.98600\n",
      "Epoch 141/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0388 - acc: 0.9848 - val_loss: 0.0803 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.98600\n",
      "Epoch 142/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0400 - acc: 0.9868 - val_loss: 0.0571 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.98600\n",
      "Epoch 143/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0351 - acc: 0.9886 - val_loss: 0.0486 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00143: val_acc improved from 0.98600 to 0.98800, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 144/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0332 - acc: 0.9888 - val_loss: 0.0864 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.98800\n",
      "Epoch 145/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0429 - acc: 0.9854 - val_loss: 0.0904 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.98800\n",
      "Epoch 146/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0625 - acc: 0.9784 - val_loss: 0.0900 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.98800\n",
      "Epoch 147/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0329 - acc: 0.9894 - val_loss: 0.0474 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.98800\n",
      "Epoch 148/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0208 - acc: 0.9924 - val_loss: 0.0648 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.98800\n",
      "Epoch 149/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0262 - acc: 0.9900 - val_loss: 0.0508 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.98800\n",
      "Epoch 150/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0263 - acc: 0.9904 - val_loss: 0.0528 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.98800\n",
      "Epoch 151/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0290 - acc: 0.9906 - val_loss: 0.0468 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.98800\n",
      "Epoch 152/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0287 - acc: 0.9910 - val_loss: 0.0588 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.98800\n",
      "Epoch 153/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0253 - acc: 0.9916 - val_loss: 0.0689 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.98800\n",
      "Epoch 154/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0229 - acc: 0.9928 - val_loss: 0.0924 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.98800\n",
      "Epoch 155/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0339 - acc: 0.9884 - val_loss: 0.0620 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.98800\n",
      "Epoch 156/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0205 - acc: 0.9926 - val_loss: 0.1349 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.98800\n",
      "Epoch 157/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0716 - acc: 0.9762 - val_loss: 0.0741 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.98800\n",
      "Epoch 158/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0400 - acc: 0.9848 - val_loss: 0.0674 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.98800\n",
      "Epoch 159/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0285 - acc: 0.9892 - val_loss: 0.0527 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.98800\n",
      "Epoch 160/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0229 - acc: 0.9910 - val_loss: 0.0680 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.98800\n",
      "Epoch 161/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0231 - acc: 0.9924 - val_loss: 0.0640 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.98800\n",
      "Epoch 162/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0204 - acc: 0.9926 - val_loss: 0.0483 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.98800\n",
      "Epoch 163/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0342 - acc: 0.9884 - val_loss: 0.0697 - val_acc: 0.9770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00163: val_acc did not improve from 0.98800\n",
      "Epoch 164/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0268 - acc: 0.9888 - val_loss: 0.0665 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.98800\n",
      "Epoch 165/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0304 - acc: 0.9886 - val_loss: 0.0510 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.98800\n",
      "Epoch 166/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0416 - acc: 0.9842 - val_loss: 0.0533 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.98800\n",
      "Epoch 167/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0317 - acc: 0.9896 - val_loss: 0.0663 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.98800\n",
      "Epoch 168/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0343 - acc: 0.9890 - val_loss: 0.1025 - val_acc: 0.9680\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.98800\n",
      "Epoch 169/500\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.0397 - acc: 0.9862 - val_loss: 0.0451 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.98800\n",
      "Epoch 170/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0369 - acc: 0.9890 - val_loss: 0.1014 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.98800\n",
      "Epoch 171/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0316 - acc: 0.9888 - val_loss: 0.0704 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.98800\n",
      "Epoch 172/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0256 - acc: 0.9904 - val_loss: 0.0482 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.98800\n",
      "Epoch 173/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0875 - acc: 0.9728 - val_loss: 0.2118 - val_acc: 0.9400\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.98800\n",
      "Epoch 174/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.1533 - acc: 0.9570 - val_loss: 0.0833 - val_acc: 0.9760\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.98800\n",
      "Epoch 175/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0438 - acc: 0.9828 - val_loss: 0.0680 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.98800\n",
      "Epoch 176/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0226 - acc: 0.9922 - val_loss: 0.1207 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.98800\n",
      "Epoch 177/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0890 - acc: 0.9706 - val_loss: 0.0742 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.98800\n",
      "Epoch 178/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0194 - acc: 0.9940 - val_loss: 0.0584 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.98800\n",
      "Epoch 179/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0195 - acc: 0.9926 - val_loss: 0.0745 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.98800\n",
      "Epoch 180/500\n",
      "5000/5000 [==============================] - 0s 51us/step - loss: 0.0284 - acc: 0.9896 - val_loss: 0.0857 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.98800\n",
      "Epoch 181/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0184 - acc: 0.9942 - val_loss: 0.0726 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.98800\n",
      "Epoch 182/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0161 - acc: 0.9946 - val_loss: 0.0539 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.98800\n",
      "Epoch 183/500\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.0134 - acc: 0.9956 - val_loss: 0.0538 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.98800\n",
      "Epoch 184/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0157 - acc: 0.9956 - val_loss: 0.0431 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.98800\n",
      "Epoch 185/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0092 - acc: 0.9976 - val_loss: 0.0474 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.98800\n",
      "Epoch 186/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0087 - acc: 0.9968 - val_loss: 0.0394 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00186: val_acc improved from 0.98800 to 0.99000, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 187/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0090 - acc: 0.9968 - val_loss: 0.0430 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.99000\n",
      "Epoch 188/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0222 - acc: 0.9926 - val_loss: 0.0584 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.99000\n",
      "Epoch 189/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0324 - acc: 0.9878 - val_loss: 0.1398 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.99000\n",
      "Epoch 190/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.1067 - acc: 0.9658 - val_loss: 0.0769 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.99000\n",
      "Epoch 191/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0393 - acc: 0.9868 - val_loss: 0.0624 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.99000\n",
      "Epoch 192/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0166 - acc: 0.9958 - val_loss: 0.0671 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.99000\n",
      "Epoch 193/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0141 - acc: 0.9946 - val_loss: 0.0494 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.99000\n",
      "Epoch 194/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0188 - acc: 0.9938 - val_loss: 0.0536 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.99000\n",
      "Epoch 195/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0183 - acc: 0.9932 - val_loss: 0.0641 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.99000\n",
      "Epoch 196/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0772 - acc: 0.9748 - val_loss: 0.0701 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.99000\n",
      "Epoch 197/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0227 - acc: 0.9926 - val_loss: 0.0677 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.99000\n",
      "Epoch 198/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0639 - acc: 0.9782 - val_loss: 0.0580 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.99000\n",
      "Epoch 199/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0199 - acc: 0.9940 - val_loss: 0.0499 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.99000\n",
      "Epoch 200/500\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.0160 - acc: 0.9942 - val_loss: 0.0535 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.99000\n",
      "Epoch 201/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0129 - acc: 0.9964 - val_loss: 0.2053 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00201: val_acc did not improve from 0.99000\n",
      "Epoch 202/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.1216 - acc: 0.9622 - val_loss: 0.0569 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00202: val_acc did not improve from 0.99000\n",
      "Epoch 203/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0371 - acc: 0.9898 - val_loss: 0.0473 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00203: val_acc did not improve from 0.99000\n",
      "Epoch 204/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0213 - acc: 0.9940 - val_loss: 0.0420 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00204: val_acc did not improve from 0.99000\n",
      "Epoch 205/500\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.0201 - acc: 0.9934 - val_loss: 0.0479 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00205: val_acc did not improve from 0.99000\n",
      "Epoch 206/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0130 - acc: 0.9950 - val_loss: 0.0441 - val_acc: 0.9890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00206: val_acc did not improve from 0.99000\n",
      "Epoch 207/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0133 - acc: 0.9952 - val_loss: 0.0414 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.99000\n",
      "Epoch 208/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0239 - acc: 0.9906 - val_loss: 0.0612 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00208: val_acc did not improve from 0.99000\n",
      "Epoch 209/500\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.0170 - acc: 0.9942 - val_loss: 0.0716 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00209: val_acc did not improve from 0.99000\n",
      "Epoch 210/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0189 - acc: 0.9930 - val_loss: 0.0647 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00210: val_acc did not improve from 0.99000\n",
      "Epoch 211/500\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.0174 - acc: 0.9944 - val_loss: 0.0676 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.99000\n",
      "Epoch 212/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0131 - acc: 0.9960 - val_loss: 0.0511 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.99000\n",
      "Epoch 213/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0129 - acc: 0.9960 - val_loss: 0.0417 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00213: val_acc did not improve from 0.99000\n",
      "Epoch 214/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0083 - acc: 0.9968 - val_loss: 0.0478 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00214: val_acc improved from 0.99000 to 0.99100, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 215/500\n",
      "5000/5000 [==============================] - 0s 40us/step - loss: 0.0403 - acc: 0.9884 - val_loss: 0.1143 - val_acc: 0.9670\n",
      "\n",
      "Epoch 00215: val_acc did not improve from 0.99100\n",
      "Epoch 216/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0226 - acc: 0.9918 - val_loss: 0.0570 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00216: val_acc did not improve from 0.99100\n",
      "Epoch 217/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0150 - acc: 0.9956 - val_loss: 0.0496 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00217: val_acc did not improve from 0.99100\n",
      "Epoch 218/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0125 - acc: 0.9960 - val_loss: 0.0438 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00218: val_acc did not improve from 0.99100\n",
      "Epoch 219/500\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0552 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00219: val_acc did not improve from 0.99100\n",
      "Epoch 220/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0113 - acc: 0.9950 - val_loss: 0.0737 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00220: val_acc did not improve from 0.99100\n",
      "Epoch 221/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0176 - acc: 0.9936 - val_loss: 0.1112 - val_acc: 0.9690\n",
      "\n",
      "Epoch 00221: val_acc did not improve from 0.99100\n",
      "Epoch 222/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0290 - acc: 0.9888 - val_loss: 0.0504 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00222: val_acc did not improve from 0.99100\n",
      "Epoch 223/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0858 - acc: 0.9750 - val_loss: 0.1136 - val_acc: 0.9660\n",
      "\n",
      "Epoch 00223: val_acc did not improve from 0.99100\n",
      "Epoch 224/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0363 - acc: 0.9874 - val_loss: 0.0499 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00224: val_acc did not improve from 0.99100\n",
      "Epoch 225/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0144 - acc: 0.9942 - val_loss: 0.0502 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00225: val_acc did not improve from 0.99100\n",
      "Epoch 226/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0123 - acc: 0.9956 - val_loss: 0.0744 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00226: val_acc did not improve from 0.99100\n",
      "Epoch 227/500\n",
      "5000/5000 [==============================] - 0s 51us/step - loss: 0.0110 - acc: 0.9962 - val_loss: 0.0574 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00227: val_acc did not improve from 0.99100\n",
      "Epoch 228/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0098 - acc: 0.9968 - val_loss: 0.0589 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00228: val_acc did not improve from 0.99100\n",
      "Epoch 229/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0127 - acc: 0.9948 - val_loss: 0.0471 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00229: val_acc did not improve from 0.99100\n",
      "Epoch 230/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0116 - acc: 0.9954 - val_loss: 0.0446 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00230: val_acc did not improve from 0.99100\n",
      "Epoch 231/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0113 - acc: 0.9954 - val_loss: 0.0526 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00231: val_acc did not improve from 0.99100\n",
      "Epoch 232/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0307 - acc: 0.9892 - val_loss: 0.0686 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00232: val_acc did not improve from 0.99100\n",
      "Epoch 233/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0163 - acc: 0.9938 - val_loss: 0.0637 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00233: val_acc did not improve from 0.99100\n",
      "Epoch 234/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0283 - acc: 0.9898 - val_loss: 0.0790 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00234: val_acc did not improve from 0.99100\n",
      "Epoch 235/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0262 - acc: 0.9902 - val_loss: 0.0466 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00235: val_acc did not improve from 0.99100\n",
      "Epoch 236/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0107 - acc: 0.9974 - val_loss: 0.0480 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00236: val_acc did not improve from 0.99100\n",
      "Epoch 237/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0068 - acc: 0.9980 - val_loss: 0.1049 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00237: val_acc did not improve from 0.99100\n",
      "Epoch 238/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0146 - acc: 0.9946 - val_loss: 0.0558 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00238: val_acc did not improve from 0.99100\n",
      "Epoch 239/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0096 - acc: 0.9972 - val_loss: 0.0509 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00239: val_acc did not improve from 0.99100\n",
      "Epoch 240/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0131 - acc: 0.9948 - val_loss: 0.0512 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00240: val_acc did not improve from 0.99100\n",
      "Epoch 241/500\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.0248 - acc: 0.9918 - val_loss: 0.0563 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00241: val_acc did not improve from 0.99100\n",
      "Epoch 242/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0211 - acc: 0.9934 - val_loss: 0.1314 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00242: val_acc did not improve from 0.99100\n",
      "Epoch 243/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0825 - acc: 0.9728 - val_loss: 0.0987 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00243: val_acc did not improve from 0.99100\n",
      "Epoch 244/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0362 - acc: 0.9872 - val_loss: 0.0578 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00244: val_acc did not improve from 0.99100\n",
      "Epoch 245/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0789 - acc: 0.9730 - val_loss: 0.0889 - val_acc: 0.9680\n",
      "\n",
      "Epoch 00245: val_acc did not improve from 0.99100\n",
      "Epoch 246/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0270 - acc: 0.9920 - val_loss: 0.0467 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00246: val_acc did not improve from 0.99100\n",
      "Epoch 247/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0135 - acc: 0.9950 - val_loss: 0.0560 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00247: val_acc did not improve from 0.99100\n",
      "Epoch 248/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0106 - acc: 0.9966 - val_loss: 0.0388 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00248: val_acc did not improve from 0.99100\n",
      "Epoch 249/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0452 - acc: 0.9846 - val_loss: 0.0930 - val_acc: 0.9730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00249: val_acc did not improve from 0.99100\n",
      "Epoch 250/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0685 - acc: 0.9756 - val_loss: 0.0719 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00250: val_acc did not improve from 0.99100\n",
      "Epoch 251/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0254 - acc: 0.9902 - val_loss: 0.0446 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00251: val_acc did not improve from 0.99100\n",
      "Epoch 252/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0297 - acc: 0.9904 - val_loss: 0.0449 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00252: val_acc did not improve from 0.99100\n",
      "Epoch 253/500\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.0258 - acc: 0.9918 - val_loss: 0.0923 - val_acc: 0.9760\n",
      "\n",
      "Epoch 00253: val_acc did not improve from 0.99100\n",
      "Epoch 254/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0226 - acc: 0.9930 - val_loss: 0.0721 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00254: val_acc did not improve from 0.99100\n",
      "Epoch 255/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0138 - acc: 0.9952 - val_loss: 0.0476 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00255: val_acc did not improve from 0.99100\n",
      "Epoch 256/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0517 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00256: val_acc did not improve from 0.99100\n",
      "Epoch 257/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0076 - acc: 0.9964 - val_loss: 0.0829 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00257: val_acc did not improve from 0.99100\n",
      "Epoch 258/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0279 - acc: 0.9904 - val_loss: 0.0835 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00258: val_acc did not improve from 0.99100\n",
      "Epoch 259/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0120 - acc: 0.9956 - val_loss: 0.0534 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00259: val_acc did not improve from 0.99100\n",
      "Epoch 260/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0101 - acc: 0.9962 - val_loss: 0.0638 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00260: val_acc did not improve from 0.99100\n",
      "Epoch 261/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0617 - acc: 0.9818 - val_loss: 0.0563 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00261: val_acc did not improve from 0.99100\n",
      "Epoch 262/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0177 - acc: 0.9940 - val_loss: 0.0476 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00262: val_acc did not improve from 0.99100\n",
      "Epoch 263/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0076 - acc: 0.9972 - val_loss: 0.0364 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00263: val_acc did not improve from 0.99100\n",
      "Epoch 264/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0173 - acc: 0.9940 - val_loss: 0.0541 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00264: val_acc did not improve from 0.99100\n",
      "Epoch 265/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0162 - acc: 0.9942 - val_loss: 0.0625 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00265: val_acc did not improve from 0.99100\n",
      "Epoch 266/500\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.0085 - acc: 0.9984 - val_loss: 0.0406 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00266: val_acc did not improve from 0.99100\n",
      "Epoch 267/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0067 - acc: 0.9978 - val_loss: 0.0544 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00267: val_acc did not improve from 0.99100\n",
      "Epoch 268/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0204 - acc: 0.9948 - val_loss: 0.1006 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00268: val_acc did not improve from 0.99100\n",
      "Epoch 269/500\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.0298 - acc: 0.9896 - val_loss: 0.1050 - val_acc: 0.9690\n",
      "\n",
      "Epoch 00269: val_acc did not improve from 0.99100\n",
      "Epoch 270/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0169 - acc: 0.9944 - val_loss: 0.0498 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00270: val_acc did not improve from 0.99100\n",
      "Epoch 271/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0122 - acc: 0.9950 - val_loss: 0.0464 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00271: val_acc did not improve from 0.99100\n",
      "Epoch 272/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0065 - acc: 0.9972 - val_loss: 0.0371 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00272: val_acc did not improve from 0.99100\n",
      "Epoch 273/500\n",
      "5000/5000 [==============================] - 0s 42us/step - loss: 0.0054 - acc: 0.9984 - val_loss: 0.0515 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00273: val_acc did not improve from 0.99100\n",
      "Epoch 274/500\n",
      "5000/5000 [==============================] - 0s 42us/step - loss: 0.0202 - acc: 0.9938 - val_loss: 0.0617 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00274: val_acc did not improve from 0.99100\n",
      "Epoch 275/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0166 - acc: 0.9938 - val_loss: 0.0759 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00275: val_acc did not improve from 0.99100\n",
      "Epoch 276/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0145 - acc: 0.9954 - val_loss: 0.0603 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00276: val_acc did not improve from 0.99100\n",
      "Epoch 277/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0112 - acc: 0.9954 - val_loss: 0.0479 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00277: val_acc did not improve from 0.99100\n",
      "Epoch 278/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0184 - acc: 0.9944 - val_loss: 0.0703 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00278: val_acc did not improve from 0.99100\n",
      "Epoch 279/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0120 - acc: 0.9964 - val_loss: 0.0483 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00279: val_acc did not improve from 0.99100\n",
      "Epoch 280/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0097 - acc: 0.9970 - val_loss: 0.0533 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00280: val_acc did not improve from 0.99100\n",
      "Epoch 281/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0058 - acc: 0.9982 - val_loss: 0.0440 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00281: val_acc did not improve from 0.99100\n",
      "Epoch 282/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0085 - acc: 0.9978 - val_loss: 0.0469 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00282: val_acc did not improve from 0.99100\n",
      "Epoch 283/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0041 - acc: 0.9988 - val_loss: 0.0442 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00283: val_acc did not improve from 0.99100\n",
      "Epoch 284/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0056 - acc: 0.9978 - val_loss: 0.0568 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00284: val_acc did not improve from 0.99100\n",
      "Epoch 285/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0105 - acc: 0.9964 - val_loss: 0.0477 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00285: val_acc did not improve from 0.99100\n",
      "Epoch 286/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0112 - acc: 0.9962 - val_loss: 0.0568 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00286: val_acc did not improve from 0.99100\n",
      "Epoch 287/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0147 - acc: 0.9960 - val_loss: 0.0645 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00287: val_acc did not improve from 0.99100\n",
      "Epoch 288/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0246 - acc: 0.9920 - val_loss: 0.0481 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00288: val_acc did not improve from 0.99100\n",
      "Epoch 289/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0117 - acc: 0.9958 - val_loss: 0.0430 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00289: val_acc did not improve from 0.99100\n",
      "Epoch 290/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0059 - acc: 0.9978 - val_loss: 0.0600 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00290: val_acc did not improve from 0.99100\n",
      "Epoch 291/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0108 - acc: 0.9966 - val_loss: 0.0788 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00291: val_acc did not improve from 0.99100\n",
      "Epoch 292/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0284 - acc: 0.9898 - val_loss: 0.0779 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00292: val_acc did not improve from 0.99100\n",
      "Epoch 293/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0290 - acc: 0.9906 - val_loss: 0.1537 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00293: val_acc did not improve from 0.99100\n",
      "Epoch 294/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0312 - acc: 0.9884 - val_loss: 0.0781 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00294: val_acc did not improve from 0.99100\n",
      "Epoch 295/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0282 - acc: 0.9914 - val_loss: 0.0826 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00295: val_acc did not improve from 0.99100\n",
      "Epoch 296/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0131 - acc: 0.9958 - val_loss: 0.0399 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00296: val_acc did not improve from 0.99100\n",
      "Epoch 297/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0400 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00297: val_acc did not improve from 0.99100\n",
      "Epoch 298/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0040 - acc: 0.9992 - val_loss: 0.0636 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00298: val_acc did not improve from 0.99100\n",
      "Epoch 299/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0457 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00299: val_acc did not improve from 0.99100\n",
      "Epoch 300/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0128 - acc: 0.9968 - val_loss: 0.0514 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00300: val_acc did not improve from 0.99100\n",
      "Epoch 301/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0105 - acc: 0.9968 - val_loss: 0.0566 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00301: val_acc did not improve from 0.99100\n",
      "Epoch 302/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0509 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00302: val_acc did not improve from 0.99100\n",
      "Epoch 303/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0563 - acc: 0.9834 - val_loss: 0.1055 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00303: val_acc did not improve from 0.99100\n",
      "Epoch 304/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0148 - acc: 0.9952 - val_loss: 0.0526 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00304: val_acc did not improve from 0.99100\n",
      "Epoch 305/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0071 - acc: 0.9970 - val_loss: 0.0582 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00305: val_acc did not improve from 0.99100\n",
      "Epoch 306/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0055 - acc: 0.9978 - val_loss: 0.0417 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00306: val_acc did not improve from 0.99100\n",
      "Epoch 307/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0069 - acc: 0.9982 - val_loss: 0.0517 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00307: val_acc did not improve from 0.99100\n",
      "Epoch 308/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0091 - acc: 0.9964 - val_loss: 0.0749 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00308: val_acc did not improve from 0.99100\n",
      "Epoch 309/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0060 - acc: 0.9980 - val_loss: 0.0555 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00309: val_acc did not improve from 0.99100\n",
      "Epoch 310/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0058 - acc: 0.9982 - val_loss: 0.0780 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00310: val_acc did not improve from 0.99100\n",
      "Epoch 311/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0043 - acc: 0.9988 - val_loss: 0.0749 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00311: val_acc did not improve from 0.99100\n",
      "Epoch 312/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0106 - acc: 0.9958 - val_loss: 0.0502 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00312: val_acc did not improve from 0.99100\n",
      "Epoch 313/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0230 - acc: 0.9918 - val_loss: 0.0635 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00313: val_acc did not improve from 0.99100\n",
      "Epoch 314/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0206 - acc: 0.9912 - val_loss: 0.0430 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00314: val_acc did not improve from 0.99100\n",
      "Epoch 315/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0175 - acc: 0.9948 - val_loss: 0.0376 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00315: val_acc did not improve from 0.99100\n",
      "Epoch 316/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0072 - acc: 0.9976 - val_loss: 0.0330 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00316: val_acc improved from 0.99100 to 0.99200, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 317/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0054 - acc: 0.9982 - val_loss: 0.0484 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00317: val_acc did not improve from 0.99200\n",
      "Epoch 318/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0231 - acc: 0.9930 - val_loss: 0.0825 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00318: val_acc did not improve from 0.99200\n",
      "Epoch 319/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0216 - acc: 0.9936 - val_loss: 0.0823 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00319: val_acc did not improve from 0.99200\n",
      "Epoch 320/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0226 - acc: 0.9932 - val_loss: 0.0751 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00320: val_acc did not improve from 0.99200\n",
      "Epoch 321/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0186 - acc: 0.9940 - val_loss: 0.1043 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00321: val_acc did not improve from 0.99200\n",
      "Epoch 322/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0332 - acc: 0.9912 - val_loss: 0.0478 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00322: val_acc did not improve from 0.99200\n",
      "Epoch 323/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0111 - acc: 0.9958 - val_loss: 0.0554 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00323: val_acc did not improve from 0.99200\n",
      "Epoch 324/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0050 - acc: 0.9980 - val_loss: 0.0490 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00324: val_acc did not improve from 0.99200\n",
      "Epoch 325/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0105 - acc: 0.9966 - val_loss: 0.0496 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00325: val_acc did not improve from 0.99200\n",
      "Epoch 326/500\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.0118 - acc: 0.9962 - val_loss: 0.0878 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00326: val_acc did not improve from 0.99200\n",
      "Epoch 327/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0407 - acc: 0.9862 - val_loss: 0.0956 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00327: val_acc did not improve from 0.99200\n",
      "Epoch 328/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0425 - acc: 0.9858 - val_loss: 0.1136 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00328: val_acc did not improve from 0.99200\n",
      "Epoch 329/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0162 - acc: 0.9934 - val_loss: 0.0510 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00329: val_acc did not improve from 0.99200\n",
      "Epoch 330/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0086 - acc: 0.9976 - val_loss: 0.0472 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00330: val_acc did not improve from 0.99200\n",
      "Epoch 331/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0230 - acc: 0.9936 - val_loss: 0.0437 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00331: val_acc improved from 0.99200 to 0.99200, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 332/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0324 - acc: 0.9900 - val_loss: 0.0500 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00332: val_acc did not improve from 0.99200\n",
      "Epoch 333/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0103 - acc: 0.9964 - val_loss: 0.0347 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00333: val_acc did not improve from 0.99200\n",
      "Epoch 334/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0035 - acc: 0.9992 - val_loss: 0.0480 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00334: val_acc did not improve from 0.99200\n",
      "Epoch 335/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0047 - acc: 0.9988 - val_loss: 0.0585 - val_acc: 0.9890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00335: val_acc did not improve from 0.99200\n",
      "Epoch 336/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0034 - acc: 0.9992 - val_loss: 0.0516 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00336: val_acc did not improve from 0.99200\n",
      "Epoch 337/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0096 - acc: 0.9964 - val_loss: 0.0773 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00337: val_acc did not improve from 0.99200\n",
      "Epoch 338/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0104 - acc: 0.9966 - val_loss: 0.0403 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00338: val_acc did not improve from 0.99200\n",
      "Epoch 339/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0055 - acc: 0.9980 - val_loss: 0.0413 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00339: val_acc did not improve from 0.99200\n",
      "Epoch 340/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0166 - acc: 0.9934 - val_loss: 0.0796 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00340: val_acc did not improve from 0.99200\n",
      "Epoch 341/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0137 - acc: 0.9936 - val_loss: 0.0780 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00341: val_acc did not improve from 0.99200\n",
      "Epoch 342/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0196 - acc: 0.9938 - val_loss: 0.0946 - val_acc: 0.9760\n",
      "\n",
      "Epoch 00342: val_acc did not improve from 0.99200\n",
      "Epoch 343/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0123 - acc: 0.9950 - val_loss: 0.0736 - val_acc: 0.9760\n",
      "\n",
      "Epoch 00343: val_acc did not improve from 0.99200\n",
      "Epoch 344/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0112 - acc: 0.9962 - val_loss: 0.0482 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00344: val_acc did not improve from 0.99200\n",
      "Epoch 345/500\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.0155 - acc: 0.9946 - val_loss: 0.0614 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00345: val_acc did not improve from 0.99200\n",
      "Epoch 346/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0130 - acc: 0.9960 - val_loss: 0.0487 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00346: val_acc did not improve from 0.99200\n",
      "Epoch 347/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0144 - acc: 0.9960 - val_loss: 0.0663 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00347: val_acc did not improve from 0.99200\n",
      "Epoch 348/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0072 - acc: 0.9986 - val_loss: 0.0421 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00348: val_acc did not improve from 0.99200\n",
      "Epoch 349/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0081 - acc: 0.9974 - val_loss: 0.0512 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00349: val_acc did not improve from 0.99200\n",
      "Epoch 350/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0148 - acc: 0.9954 - val_loss: 0.0817 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00350: val_acc did not improve from 0.99200\n",
      "Epoch 351/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0079 - acc: 0.9968 - val_loss: 0.1564 - val_acc: 0.9710\n",
      "\n",
      "Epoch 00351: val_acc did not improve from 0.99200\n",
      "Epoch 352/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.1536 - acc: 0.9538 - val_loss: 0.0662 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00352: val_acc did not improve from 0.99200\n",
      "Epoch 353/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0269 - acc: 0.9916 - val_loss: 0.0577 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00353: val_acc did not improve from 0.99200\n",
      "Epoch 354/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0098 - acc: 0.9974 - val_loss: 0.0519 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00354: val_acc did not improve from 0.99200\n",
      "Epoch 355/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0095 - acc: 0.9968 - val_loss: 0.0404 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00355: val_acc did not improve from 0.99200\n",
      "Epoch 356/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0104 - acc: 0.9968 - val_loss: 0.0529 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00356: val_acc did not improve from 0.99200\n",
      "Epoch 357/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0067 - acc: 0.9972 - val_loss: 0.0730 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00357: val_acc did not improve from 0.99200\n",
      "Epoch 358/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0066 - acc: 0.9984 - val_loss: 0.0338 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00358: val_acc did not improve from 0.99200\n",
      "Epoch 359/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0074 - acc: 0.9978 - val_loss: 0.0552 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00359: val_acc did not improve from 0.99200\n",
      "Epoch 360/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0036 - acc: 0.9992 - val_loss: 0.0622 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00360: val_acc did not improve from 0.99200\n",
      "Epoch 361/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0103 - acc: 0.9972 - val_loss: 0.0866 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00361: val_acc did not improve from 0.99200\n",
      "Epoch 362/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0223 - acc: 0.9934 - val_loss: 0.0435 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00362: val_acc did not improve from 0.99200\n",
      "Epoch 363/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0139 - acc: 0.9950 - val_loss: 0.0557 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00363: val_acc did not improve from 0.99200\n",
      "Epoch 364/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0076 - acc: 0.9978 - val_loss: 0.0425 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00364: val_acc did not improve from 0.99200\n",
      "Epoch 365/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0094 - acc: 0.9968 - val_loss: 0.0518 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00365: val_acc did not improve from 0.99200\n",
      "Epoch 366/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0065 - acc: 0.9980 - val_loss: 0.0693 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00366: val_acc did not improve from 0.99200\n",
      "Epoch 367/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0132 - acc: 0.9952 - val_loss: 0.0474 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00367: val_acc did not improve from 0.99200\n",
      "Epoch 368/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.0497 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00368: val_acc did not improve from 0.99200\n",
      "Epoch 369/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.0540 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00369: val_acc did not improve from 0.99200\n",
      "Epoch 370/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0032 - acc: 0.9990 - val_loss: 0.0741 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00370: val_acc did not improve from 0.99200\n",
      "Epoch 371/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0273 - acc: 0.9910 - val_loss: 0.0819 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00371: val_acc did not improve from 0.99200\n",
      "Epoch 372/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0089 - acc: 0.9972 - val_loss: 0.0455 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00372: val_acc did not improve from 0.99200\n",
      "Epoch 373/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0023 - acc: 0.9992 - val_loss: 0.0431 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00373: val_acc did not improve from 0.99200\n",
      "Epoch 374/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0043 - acc: 0.9988 - val_loss: 0.0384 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00374: val_acc did not improve from 0.99200\n",
      "Epoch 375/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 0.0637 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00375: val_acc did not improve from 0.99200\n",
      "Epoch 376/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0141 - acc: 0.9950 - val_loss: 0.0528 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00376: val_acc did not improve from 0.99200\n",
      "Epoch 377/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0120 - acc: 0.9970 - val_loss: 0.0543 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00377: val_acc did not improve from 0.99200\n",
      "Epoch 378/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0077 - acc: 0.9968 - val_loss: 0.0986 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00378: val_acc did not improve from 0.99200\n",
      "Epoch 379/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.1370 - acc: 0.9604 - val_loss: 0.1056 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00379: val_acc did not improve from 0.99200\n",
      "Epoch 380/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0269 - acc: 0.9906 - val_loss: 0.0604 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00380: val_acc did not improve from 0.99200\n",
      "Epoch 381/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0149 - acc: 0.9950 - val_loss: 0.0601 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00381: val_acc did not improve from 0.99200\n",
      "Epoch 382/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0122 - acc: 0.9966 - val_loss: 0.0904 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00382: val_acc did not improve from 0.99200\n",
      "Epoch 383/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0095 - acc: 0.9972 - val_loss: 0.0748 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00383: val_acc did not improve from 0.99200\n",
      "Epoch 384/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0162 - acc: 0.9950 - val_loss: 0.0681 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00384: val_acc did not improve from 0.99200\n",
      "Epoch 385/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0082 - acc: 0.9972 - val_loss: 0.0434 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00385: val_acc did not improve from 0.99200\n",
      "Epoch 386/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0053 - acc: 0.9978 - val_loss: 0.0820 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00386: val_acc did not improve from 0.99200\n",
      "Epoch 387/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0604 - acc: 0.9828 - val_loss: 0.1028 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00387: val_acc did not improve from 0.99200\n",
      "Epoch 388/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0339 - acc: 0.9890 - val_loss: 0.0712 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00388: val_acc did not improve from 0.99200\n",
      "Epoch 389/500\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.0085 - acc: 0.9978 - val_loss: 0.0522 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00389: val_acc did not improve from 0.99200\n",
      "Epoch 390/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0126 - acc: 0.9958 - val_loss: 0.0445 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00390: val_acc did not improve from 0.99200\n",
      "Epoch 391/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0720 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00391: val_acc did not improve from 0.99200\n",
      "Epoch 392/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0853 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00392: val_acc did not improve from 0.99200\n",
      "Epoch 393/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0118 - acc: 0.9958 - val_loss: 0.0730 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00393: val_acc did not improve from 0.99200\n",
      "Epoch 394/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0083 - acc: 0.9976 - val_loss: 0.0731 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00394: val_acc did not improve from 0.99200\n",
      "Epoch 395/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0140 - acc: 0.9956 - val_loss: 0.1108 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00395: val_acc did not improve from 0.99200\n",
      "Epoch 396/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0192 - acc: 0.9948 - val_loss: 0.0547 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00396: val_acc did not improve from 0.99200\n",
      "Epoch 397/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0101 - acc: 0.9968 - val_loss: 0.1268 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00397: val_acc did not improve from 0.99200\n",
      "Epoch 398/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0108 - acc: 0.9968 - val_loss: 0.0874 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00398: val_acc did not improve from 0.99200\n",
      "Epoch 399/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0182 - acc: 0.9944 - val_loss: 0.0700 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00399: val_acc did not improve from 0.99200\n",
      "Epoch 400/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0093 - acc: 0.9976 - val_loss: 0.0741 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00400: val_acc did not improve from 0.99200\n",
      "Epoch 401/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0222 - acc: 0.9952 - val_loss: 0.0866 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00401: val_acc did not improve from 0.99200\n",
      "Epoch 402/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0189 - acc: 0.9932 - val_loss: 0.0908 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00402: val_acc did not improve from 0.99200\n",
      "Epoch 403/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0263 - acc: 0.9916 - val_loss: 0.0865 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00403: val_acc did not improve from 0.99200\n",
      "Epoch 404/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0079 - acc: 0.9970 - val_loss: 0.0670 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00404: val_acc did not improve from 0.99200\n",
      "Epoch 405/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0096 - acc: 0.9964 - val_loss: 0.0825 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00405: val_acc did not improve from 0.99200\n",
      "Epoch 406/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0282 - acc: 0.9902 - val_loss: 0.0813 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00406: val_acc did not improve from 0.99200\n",
      "Epoch 407/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0126 - acc: 0.9964 - val_loss: 0.0817 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00407: val_acc did not improve from 0.99200\n",
      "Epoch 408/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0133 - acc: 0.9952 - val_loss: 0.0785 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00408: val_acc did not improve from 0.99200\n",
      "Epoch 409/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0122 - acc: 0.9950 - val_loss: 0.0673 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00409: val_acc did not improve from 0.99200\n",
      "Epoch 410/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0054 - acc: 0.9982 - val_loss: 0.0643 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00410: val_acc did not improve from 0.99200\n",
      "Epoch 411/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0038 - acc: 0.9990 - val_loss: 0.0673 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00411: val_acc did not improve from 0.99200\n",
      "Epoch 412/500\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.0654 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00412: val_acc did not improve from 0.99200\n",
      "Epoch 413/500\n",
      "5000/5000 [==============================] - 0s 42us/step - loss: 0.0033 - acc: 0.9984 - val_loss: 0.0738 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00413: val_acc did not improve from 0.99200\n",
      "Epoch 414/500\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.0063 - acc: 0.9986 - val_loss: 0.0807 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00414: val_acc did not improve from 0.99200\n",
      "Epoch 415/500\n",
      "5000/5000 [==============================] - 0s 41us/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0906 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00415: val_acc did not improve from 0.99200\n",
      "Epoch 416/500\n",
      "5000/5000 [==============================] - 0s 42us/step - loss: 0.0100 - acc: 0.9956 - val_loss: 0.1226 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00416: val_acc did not improve from 0.99200\n",
      "Epoch 417/500\n",
      "5000/5000 [==============================] - 0s 41us/step - loss: 0.0977 - acc: 0.9670 - val_loss: 0.0708 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00417: val_acc did not improve from 0.99200\n",
      "Epoch 418/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0239 - acc: 0.9916 - val_loss: 0.0617 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00418: val_acc did not improve from 0.99200\n",
      "Epoch 419/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0181 - acc: 0.9946 - val_loss: 0.0796 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00419: val_acc did not improve from 0.99200\n",
      "Epoch 420/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0107 - acc: 0.9974 - val_loss: 0.0465 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00420: val_acc did not improve from 0.99200\n",
      "Epoch 421/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0101 - acc: 0.9964 - val_loss: 0.0779 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00421: val_acc did not improve from 0.99200\n",
      "Epoch 422/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0084 - acc: 0.9976 - val_loss: 0.0574 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00422: val_acc did not improve from 0.99200\n",
      "Epoch 423/500\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.0039 - acc: 0.9990 - val_loss: 0.0636 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00423: val_acc did not improve from 0.99200\n",
      "Epoch 424/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0067 - acc: 0.9970 - val_loss: 0.1057 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00424: val_acc did not improve from 0.99200\n",
      "Epoch 425/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0039 - acc: 0.9990 - val_loss: 0.0554 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00425: val_acc did not improve from 0.99200\n",
      "Epoch 426/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0062 - acc: 0.9978 - val_loss: 0.0788 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00426: val_acc did not improve from 0.99200\n",
      "Epoch 427/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0126 - acc: 0.9952 - val_loss: 0.0823 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00427: val_acc did not improve from 0.99200\n",
      "Epoch 428/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0227 - acc: 0.9934 - val_loss: 0.1182 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00428: val_acc did not improve from 0.99200\n",
      "Epoch 429/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0113 - acc: 0.9956 - val_loss: 0.0428 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00429: val_acc did not improve from 0.99200\n",
      "Epoch 430/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0040 - acc: 0.9990 - val_loss: 0.0581 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00430: val_acc did not improve from 0.99200\n",
      "Epoch 431/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0023 - acc: 0.9992 - val_loss: 0.0527 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00431: val_acc did not improve from 0.99200\n",
      "Epoch 432/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0088 - acc: 0.9962 - val_loss: 0.0958 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00432: val_acc did not improve from 0.99200\n",
      "Epoch 433/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0117 - acc: 0.9968 - val_loss: 0.0697 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00433: val_acc did not improve from 0.99200\n",
      "Epoch 434/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0058 - acc: 0.9982 - val_loss: 0.0621 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00434: val_acc did not improve from 0.99200\n",
      "Epoch 435/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0523 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00435: val_acc did not improve from 0.99200\n",
      "Epoch 436/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0024 - acc: 0.9990 - val_loss: 0.0573 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00436: val_acc did not improve from 0.99200\n",
      "Epoch 437/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0045 - acc: 0.9994 - val_loss: 0.0626 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00437: val_acc did not improve from 0.99200\n",
      "Epoch 438/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0014 - acc: 0.9994 - val_loss: 0.0697 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00438: val_acc did not improve from 0.99200\n",
      "Epoch 439/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0153 - acc: 0.9954 - val_loss: 0.0879 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00439: val_acc did not improve from 0.99200\n",
      "Epoch 440/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0182 - acc: 0.9942 - val_loss: 0.0710 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00440: val_acc did not improve from 0.99200\n",
      "Epoch 441/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0101 - acc: 0.9974 - val_loss: 0.0894 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00441: val_acc did not improve from 0.99200\n",
      "Epoch 442/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0104 - acc: 0.9962 - val_loss: 0.0769 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00442: val_acc did not improve from 0.99200\n",
      "Epoch 443/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0122 - acc: 0.9956 - val_loss: 0.0728 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00443: val_acc did not improve from 0.99200\n",
      "Epoch 444/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0505 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00444: val_acc did not improve from 0.99200\n",
      "Epoch 445/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0039 - acc: 0.9986 - val_loss: 0.0683 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00445: val_acc did not improve from 0.99200\n",
      "Epoch 446/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 7.6891e-04 - acc: 1.0000 - val_loss: 0.0716 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00446: val_acc did not improve from 0.99200\n",
      "Epoch 447/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0610 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00447: val_acc did not improve from 0.99200\n",
      "Epoch 448/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0137 - acc: 0.9956 - val_loss: 0.1237 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00448: val_acc did not improve from 0.99200\n",
      "Epoch 449/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0108 - acc: 0.9964 - val_loss: 0.0841 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00449: val_acc did not improve from 0.99200\n",
      "Epoch 450/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0113 - acc: 0.9964 - val_loss: 0.0582 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00450: val_acc did not improve from 0.99200\n",
      "Epoch 451/500\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.0121 - acc: 0.9962 - val_loss: 0.0619 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00451: val_acc did not improve from 0.99200\n",
      "Epoch 452/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0103 - acc: 0.9966 - val_loss: 0.0940 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00452: val_acc did not improve from 0.99200\n",
      "Epoch 453/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0841 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00453: val_acc did not improve from 0.99200\n",
      "Epoch 454/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0046 - acc: 0.9984 - val_loss: 0.1118 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00454: val_acc did not improve from 0.99200\n",
      "Epoch 455/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0035 - acc: 0.9988 - val_loss: 0.1137 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00455: val_acc did not improve from 0.99200\n",
      "Epoch 456/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0144 - acc: 0.9960 - val_loss: 0.1009 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00456: val_acc did not improve from 0.99200\n",
      "Epoch 457/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0163 - acc: 0.9960 - val_loss: 0.0725 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00457: val_acc did not improve from 0.99200\n",
      "Epoch 458/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0230 - acc: 0.9926 - val_loss: 0.1253 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00458: val_acc did not improve from 0.99200\n",
      "Epoch 459/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0370 - acc: 0.9888 - val_loss: 0.1324 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00459: val_acc did not improve from 0.99200\n",
      "Epoch 460/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0128 - acc: 0.9948 - val_loss: 0.1211 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00460: val_acc did not improve from 0.99200\n",
      "Epoch 461/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0108 - acc: 0.9970 - val_loss: 0.0761 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00461: val_acc did not improve from 0.99200\n",
      "Epoch 462/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0081 - acc: 0.9972 - val_loss: 0.0902 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00462: val_acc did not improve from 0.99200\n",
      "Epoch 463/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0190 - acc: 0.9960 - val_loss: 0.0526 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00463: val_acc did not improve from 0.99200\n",
      "Epoch 464/500\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0538 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00464: val_acc did not improve from 0.99200\n",
      "Epoch 465/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0331 - acc: 0.9912 - val_loss: 0.0924 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00465: val_acc did not improve from 0.99200\n",
      "Epoch 466/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0598 - acc: 0.9798 - val_loss: 0.0536 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00466: val_acc did not improve from 0.99200\n",
      "Epoch 467/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0282 - acc: 0.9904 - val_loss: 0.0942 - val_acc: 0.9660\n",
      "\n",
      "Epoch 00467: val_acc did not improve from 0.99200\n",
      "Epoch 468/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0239 - acc: 0.9926 - val_loss: 0.0458 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00468: val_acc did not improve from 0.99200\n",
      "Epoch 469/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0397 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00469: val_acc did not improve from 0.99200\n",
      "Epoch 470/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0049 - acc: 0.9984 - val_loss: 0.0527 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00470: val_acc did not improve from 0.99200\n",
      "Epoch 471/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0106 - acc: 0.9962 - val_loss: 0.0327 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00471: val_acc improved from 0.99200 to 0.99300, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 472/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0053 - acc: 0.9988 - val_loss: 0.0489 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00472: val_acc did not improve from 0.99300\n",
      "Epoch 473/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0055 - acc: 0.9980 - val_loss: 0.0335 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00473: val_acc did not improve from 0.99300\n",
      "Epoch 474/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0335 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00474: val_acc did not improve from 0.99300\n",
      "Epoch 475/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0022 - acc: 0.9992 - val_loss: 0.0331 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00475: val_acc did not improve from 0.99300\n",
      "Epoch 476/500\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0308 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00476: val_acc did not improve from 0.99300\n",
      "Epoch 477/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0020 - acc: 0.9994 - val_loss: 0.0342 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00477: val_acc improved from 0.99300 to 0.99500, saving model to /home/nesl/Sandeep/Trained_models/Audio_Example\n",
      "Epoch 478/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 8.9160e-04 - acc: 1.0000 - val_loss: 0.0367 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00478: val_acc did not improve from 0.99500\n",
      "Epoch 479/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0015 - acc: 0.9994 - val_loss: 0.0565 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00479: val_acc did not improve from 0.99500\n",
      "Epoch 480/500\n",
      "5000/5000 [==============================] - 0s 51us/step - loss: 0.0081 - acc: 0.9972 - val_loss: 0.0895 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00480: val_acc did not improve from 0.99500\n",
      "Epoch 481/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0083 - acc: 0.9986 - val_loss: 0.0687 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00481: val_acc did not improve from 0.99500\n",
      "Epoch 482/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0162 - acc: 0.9942 - val_loss: 0.0641 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00482: val_acc did not improve from 0.99500\n",
      "Epoch 483/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0116 - acc: 0.9960 - val_loss: 0.0415 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00483: val_acc did not improve from 0.99500\n",
      "Epoch 484/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0723 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00484: val_acc did not improve from 0.99500\n",
      "Epoch 485/500\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.0209 - acc: 0.9940 - val_loss: 0.1130 - val_acc: 0.9680\n",
      "\n",
      "Epoch 00485: val_acc did not improve from 0.99500\n",
      "Epoch 486/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0371 - acc: 0.9884 - val_loss: 0.0856 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00486: val_acc did not improve from 0.99500\n",
      "Epoch 487/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0094 - acc: 0.9968 - val_loss: 0.0509 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00487: val_acc did not improve from 0.99500\n",
      "Epoch 488/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0594 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00488: val_acc did not improve from 0.99500\n",
      "Epoch 489/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0041 - acc: 0.9984 - val_loss: 0.0377 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00489: val_acc did not improve from 0.99500\n",
      "Epoch 490/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0032 - acc: 0.9988 - val_loss: 0.0264 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00490: val_acc did not improve from 0.99500\n",
      "Epoch 491/500\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.0022 - acc: 0.9992 - val_loss: 0.0506 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00491: val_acc did not improve from 0.99500\n",
      "Epoch 492/500\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.0067 - acc: 0.9978 - val_loss: 0.1057 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00492: val_acc did not improve from 0.99500\n",
      "Epoch 493/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0187 - acc: 0.9940 - val_loss: 0.0563 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00493: val_acc did not improve from 0.99500\n",
      "Epoch 494/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0222 - acc: 0.9932 - val_loss: 0.0931 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00494: val_acc did not improve from 0.99500\n",
      "Epoch 495/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0151 - acc: 0.9952 - val_loss: 0.1382 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00495: val_acc did not improve from 0.99500\n",
      "Epoch 496/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0251 - acc: 0.9922 - val_loss: 0.0631 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00496: val_acc did not improve from 0.99500\n",
      "Epoch 497/500\n",
      "5000/5000 [==============================] - 0s 42us/step - loss: 0.0066 - acc: 0.9968 - val_loss: 0.0490 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00497: val_acc did not improve from 0.99500\n",
      "Epoch 498/500\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.0035 - acc: 0.9992 - val_loss: 0.0502 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00498: val_acc did not improve from 0.99500\n",
      "Epoch 499/500\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0033 - acc: 0.9992 - val_loss: 0.0724 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00499: val_acc did not improve from 0.99500\n",
      "Epoch 500/500\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.0071 - acc: 0.9970 - val_loss: 0.1151 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00500: val_acc did not improve from 0.99500\n",
      "---Time 120.30883240699768 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 500\n",
    "batch_size=128\n",
    "\n",
    "learning_hist=sound_model.fit(Features_sound, Labels,\n",
    "                    verbose=1,\n",
    "                    epochs=epochs,\n",
    "                        shuffle=True,\n",
    "                    batch_size=batch_size,\n",
    "                        callbacks=[checkpointer],\n",
    "                    validation_data=(Features_sound2,Labels2))\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"---Time %s seconds ---\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "sound_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 53us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0006571918953224668, 0.9998]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train Accuracy\n",
    "sound_model.evaluate(Features_sound,Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 41us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03415137107289047, 0.995]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#valid Accuracy\n",
    "sound_model.evaluate(Features_sound2,Labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1377/1377 [==============================] - 0s 43us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6039950821457543, 0.9099491648511256]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test Accuracy\n",
    "sound_model.evaluate(Features_sound3,Labels3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss', 'val_acc', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(learning_hist.history.keys())\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(learning_hist.history['acc'])\n",
    "plt.plot(learning_hist.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'Valid'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAFjCAYAAACJwPcXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xl4VNX9x/H3d5KQhJAQIIGwyiaK4oYoioIoKiourSvuC3WvVatW61attbS2+nPXQotb3eveooiIiCIICMouhH0PCUnIvsz5/XEmENZJQjIT4PN6Hp5hZu69872TWT5zzj3nmnMOEREREWk8AtEuQERERES2poAmIiIi0sgooImIiIg0MgpoIiIiIo2MApqIiIhII6OAJiIiItLIKKCJyF7NzL4yM2dmA+thW1eFtvVyLdZ5KLTOQ7v7+CKy71BAExEREWlkFNBEREREGhkFNBEREZFGRgFNROokdFyVC/3/V2Y2w8yKzGy1mT1jZs1C97U0s6fNbLmZlZjZXDO7ahfbbW1mj5vZz6Hlc83sazO7wsxsJ+skm9nfzGyZmZWa2ZLQ9aQw+xAws8vM7Eszywmtu9jMnjKzNrvx9NRI6PGvMrOJof0sMbMFodrTdrLOCWb2kZktDdWbbWZzzOwFM+u2zbLdzewfoW0Wmlm+mWWa2dtmNqih909E6i422gWIyJ7NzP4O/BoYDywD+oeuH2hmQ4HvgKbAt0BG6P6XzCzonHt1m231CG2nHbAS+AhIAU4MrTfYzC5z1U4ibGbJwATgCGAj8F/8Z9sNwACgcid1xwHvAucABcA0IAc4HPgNcJ6ZDXDOLd6d52dnQmHzTeBCoBS/3/nAccCdwEVmdpJzblG1da4B/gUEgcn45zYF6Izf3wlAZmjZQ/HPeTNgLvApYEBH4Jf452pcQ+ybiOw+BTQR2V2XAoc6534GMLP2wAzgZHxgmA5c6ZwrC91/PfAi8BDw6jbbeh0fzl4Brqu2zgHAl8AlwDfAC9XWeQQfzr4HTnPObQyt0w4fenrspO5H8eHsC+By59za0HqB0DbvBV7Gh7yGcDM+nK0ANgcxM4sHRuH39XWgb7V1HghdHuecm1x9Y2bWna3D6O34cHaPc+6v2yzbEh/qRKSRUheniOyuB6rCGYBzbhU+WIBvrfl1VdAK+SeQDXQxs/2qbjSzAUAffCvWLdXXcc4tAO4LXb2j2jpNgV+Frt5SFc5C66zGt0Rtx8xaAbfgW5GGVoWz0HpBfBD6EegfaolqCL8NXf6+eiuZc64UH97ygKPN7Phq67QGcrcNZ6H1FjnnlmyzLMCYHSyb45z7YXd3QEQajgKaiOyuz3dwW2bocrpzLrv6Hc65SmBp6Gq7andVtVR94JzbtINt/hsoB7qFWukAjgSSgEXOue+3XcE59wmQu4NtDQQSgC+3rS+0XhDfUgdwzA7W3y1m1gHoApQBb+3g8XOB90NXT6h21zQg1cxeNrPDdnZMXrVlAZ43s0Fm1qQeSheRCFFAE5HdtXIHtxXs4r7q98dXu60qdC1hB5xzFcDybZatuly6i/qW7eC2rqHL86oGO2z7D9+KBZC+i23XVVXdy0OBdUcWb7MswI3AAuBKYCaQbWajzexWM2uxzfqPAZ8Bx+K7cfPN7Fsze8TM9q+XvRCRBqNj0ERkt4Ram3ZmV/dFU0zoci4wNcyycxq4lhpzzs01s0OAQcBphAZOAKcDD5rZqc656aFlC4HTzawPMATfEncM0A/4vZnd6JwbGY39EJHwFNBEpLFYFbrsuqM7zSwW6LTNslWX+22/xmY7um9F6PIH59xVtaixvlTV3cnMYnbSitZ1m2UBcM6V41vGPgM/LQm+texK4Fl8i1n15acR6u40swTgOuBJ4Gkze8c5l1cveyQi9UpdnCLSWHwduvxFaOqMbV0KxAGZoYEI4EeIFgL7h1qKtmJmQ4DUHWxrHP54ttOq5muLJOfcSnxXbhNg6Lb3m1lz/FQY4EfC7mpb6/EjTgF2OaDBOVfinHsaWIQ/Bm9nI1xFJMoU0ESkUXDOfY0PXC3xrTtxVfeFjpl6NHT18WrrFOGnpAB4xsxSq63TFvj7Th5rLX6qjjTgAzPbrtXOzFLN7PpQy11D+L/Q5fDqE8yGDuZ/Fh8sv3fOfRO6vamZ3b6TCWzPDF1WHaOHmd20o2PNQl2k++G7n3d2jKCIRJm6OEWkMbkEP3fZVcAgM5uEn4j1JPyAgjfxc6hVdx9+BOgxQKaZjcd/tg0C5uEncz2W7d0FdADOBeab2Qz8YIMAvnvx0NB2XgEq6msHq3kOfwzZBcDsUN1VE9V2wIenS6st3wR4Avibmf2IbwVzwAH4yXUrgLurLX8d8JyZLQJmA0X4AQfHhfbrb865NQ2wXyJSD9SCJiKNRmg+tSPwrUul+G6+4/EH8l8FXFr9LAKhdTbhA9rj+O7Os0LbGIkPdtXnYKu+Xplz7jx8QBuDb1X6JX4Kjlj8fG2nOedK6nMfqz1+EN+9eQ2+5fD40OOXhPald/X50fAjX28C3sNPQHs6vuUsEd+KeIRz7uNqy98PjMA/J/2B8/CT034GnOGc+11D7JeI1A/b5rNORERERKJMLWgiIiIijYwCmoiIiEgjo4AmIiIi0sgooImIiIg0MgpoIiIiIo3MHj8PWlpamuvcuXO0yxAREREJa/r06Rucc+nhltvjA1rnzp2ZNm1atMsQERERCcvMltVkOXVxioiIiDQyCmgiIiIijYwCmoiIiEgjo4AmIiIi0sgooImIiIg0MgpoIiIiIo2MApqIiIhII7PHz4MmIiKyN8rLy2PDhg2UlZVFuxTZhZiYGJKTk2nZsiXx8fH1tl0FNBERkUampKSEdevW0aFDBxITEzGzaJckO+Cco7y8nPz8fJYvX06nTp3qLaSpizOMr3/O4tNZa6JdhoiI7EOysrJIT0+nadOmCmeNmJnRpEkT0tLSaNGiBTk5OfW2bQW0MF79bhlPf7ko2mWIiMg+pKSkhGbNmkW7DKmFlJQUNm3aVG/bU0ALI2C+CVNERCRSKioqiI3VUUh7kri4OCorK+ttewpoYZiB8pmIiESaujb3LPX991JAC8MwHEpoIiIiEjkKaGEEAmpBExER2ZNdddVVe1yLpAJaGIYRVEITERFpEDNnzuShhx5i6dKl0S6lUVFAC8MMdXCKiIg0kJkzZ/Lwww83aEAbOXIkxcXFDbb9hqCAFoaZqYtTRESkEaisrKSoqKjW68XFxZGQkNAAFTUcBbQwDE2zISIi0hAeeughrr76agBOPPFEzAwz46qrruLll1/GzPjiiy945JFH6NatGwkJCbzzzjsAfP7551x00UV07dqVxMREUlNTOfXUU5kwYcJ2j7OjY9CqbsvLy+PGG2+kdevWJCQkcNxxxzFlypSG3/kwNMlKGAF1cYqIiDSIc889lzVr1jBixAjuvfdeevbsCUC3bt1YsGABAHfeeSfl5eVce+21pKSkcMABBwDw8ssvk5OTwxVXXEGHDh1YtWoV//znPxk0aBDjx4+nf//+Naph8ODBpKen8+CDD5Kdnc0TTzzBkCFDWLJkCcnJyQ2z4zWggBaGmQYJiIiINIRDDz2UY489lhEjRnDKKacwcODAzfdVBbTi4mJmzJhB06ZNt1p35MiRJCUlbXXbDTfcwMEHH8zw4cNrHNB69+7N888/v/n6QQcdxIUXXsgbb7zB9ddfX8c9230KaGH4Ls5oVyEiIgIPfzKHuavzo13GVg5ql8Ifzjq4wbZ/4403bhfOgK3CWUFBAaWlpcTExNC3b18mT55c4+3ffvvtW10/6aSTAFi4cGEdK64fCmhhaJCAiIhI9PTo0WOHt2dmZnLfffcxZswYcnNzt7qvNnOede3adavrrVq1AiA7O7uWldYvBbQwTOfiFBGRRqIhW6oaqx21nhUUFDBgwAAKCwu57bbbOOSQQ0hOTiYQCDB8+HC+/PLLGm8/JiZmh7dH+7tfAS0MDRIQERFpOHWZ4X/cuHGsXr2aUaNGbR4FWuX++++vr9KiStNshGGoi1NERKShNGvWDICcnJwar1PV6rVtK9fnn3/eKKbIqA9qQQvDDI3iFBERaSBHHXUUgUCARx99lI0bN5KUlESXLl12uc7xxx9PRkYGd9xxB0uXLqVDhw7MnDmT1157jUMOOYRZs2ZFqPqGoxa0MMxMXZwiIiINpFOnTowaNYri4mJuvPFGLr74Yl544YVdrpOamsqYMWPo27cvzzzzDHfccQdz585l9OjR9O7dO0KVNyyL9kFwu6tPnz5u2rRpDbb9ez+Yxedz1jLt/lMa7DFERESqmzdv3uZJW2XPUZO/m5lNd871CbetqHdxmtnOEmKhc65ZRIvZAc2DJiIiIpEW9YAWMhEYsc1t5dEoZFsBdXGKiIhIhDWWgLbYOffvaBexIxokICIiIpHWaAYJmFkTM4t6l+a21MUpIiIikdZYAtr5QBGwyczWm9kzZtY82kVB1amelNBEREQkchpDF+f3wLvAIiAFOAP4NXCCmfVzzhVEszh/qqdoViAiIiL7mqgHNOdc321uetXMfgIeBW4NXW7FzK4DrgM/f0pD0iABERERibTG0sW5rb8BZcCQHd3pnBvhnOvjnOuTnp7eoIX4Y9AU0URERCRyGmVAc86VA6uBtGjX4kdxRrsKERER2Zc0yoBmZglAB2BdtGvxXZxKaCIiIhI5UQ1oZtZqJ3c9gj8+7pMIlrNjGiQgIiIiERbtQQL3m9kxwHhgOdAMP4rzRGAK8EwUawPAMAU0ERERiahod3F+BeQDVwJPAg8DLYH7gIHOueLoleYFDHVxioiI7IGOP/54unfvvtVtl112GbGxNWufWrRoEWbGn/70p4Yob5eiGtCccx855wY759o75xKcc0nOucOdc392zpVEs7YqGiQgIiLSMC644ALMjJkzZ+50GeccXbp0ITU1leLiqLfbREy0W9AaPd/FqYQmIiJS34YNGwbASy+9tNNlxo8fz9KlSxk6dCiJiYm7/ZgvvfQShYWFu72dhqaAFobv4hQREZH6duqpp9KxY0def/11ysrKdrhMVXirCnO7Ky4ujvj4+HrZVkNSQAvHNEhARESkIQQCAa666iqys7P5+OOPt7s/Pz+f9957j169enHUUUcB8MYbb3DWWWfRqVMn4uPjSU9P59xzz2X27Nk1esydHYP29ddf069fPxITE8nIyOA3v/lNVFvaFNDCCJi/VDeniIhI/bv66qsxsx12c7711lsUFxdv1Xr27LPPEhsby/XXX89zzz3HsGHD+Oqrr+jXrx+ZmZl1qmHSpEmccsopZGZmcs8993D33XczefJkrr766jrv1+6K9jQbjZ7hE5pzfsCAiIiI1J8uXbpw4oknMmbMGNasWUPbtm033/fSSy/RpEkTLrvsss23jR07lqSkpK22cdlll9G7d2+eeuopnn766VrXcNtttwHw7bffbh71edNNN9GvX7+67FK9UEALoyqUBZ0jgBKaiIhE0af3wNpZ0a5iaxmHwOl/2a1NDBs2jC+//JJXX32Vu+++G4D58+czefJkzj//fNLStpz5sSqcOefYtGkTZWVlZGRk0L17d6ZMmVLrx169ejVTp05l6NChW03JER8fz2233cYVV1yxW/tWV+riDGNzF2d0yxAREdlrnXvuuaSmpm7VzTlq1CgArrnmmq2WnT59OmeccQbJyck0b96c9PR00tPTmTdvHhs3bqz1Yy9evBiAAw88cLv7DjrooFpvr76oBS0Msy1dnCIiIlG1my1VjVVCQgKXXHIJzz//PJMmTaJv37689tprdOjQgcGDB29ebunSpQwYMICWLVvy4IMP0qNHD5KSkjAzbrnlFsrLy6O4F/VLAa2GgkpoIiIiDWbYsGE8//zzvPTSS+Tk5LB27Vruu+8+AoEtnX3vvfceRUVFfPbZZ/Tv33/z7c45NmzYQPPmzWv9uF27dgV8l+q25s6dW4c9qR8KaGEENDJARESkwfXu3ZvDDz+ct99+m5UrV2Jm23VvxsTEANvPrPDiiy/WOaC1a9eOPn368MEHH5CZmUm3bt0AKC0t5cknn6zj3uw+BbQwqg8SEBERkYYzbNgwbrnlFj777DMGDhy4uXWrypAhQ7j33nu59NJLufnmm2nevDnffPMNY8aMoUuXLnV+3CeeeIJBgwbRr18/brrpJpo3b84bb7wR1Sm2NEggjKr2M+UzERGRhnXppZeSkJAAbD84AGD//fdn9OjRdOrUiUcffZR7772XvLw8vv76a9q1a1fnx+3fvz+ff/45Xbt2Zfjw4QwfPpy+ffvu8hRUDc329AlY+/Tp46ZNm9Zg2x/59WIeHT2P2Q8Pplm8GhxFRKThzZs3j549e0a7DKmlmvzdzGy6c65PuG2pBS0MdXGKiIhIpCmghaFpNkRERCTSFNDC2DyGUwFNREREIkQBLQx1cYqIiEikKaCFUTUPmuKZiIiIRIoCWhhVLWh7+mhXERER2XMooIVRdQxaUPlMREREIkQBLYzNozjVySkiIhGknps9S33/vRTQwth8Kk69T0REJELi4uIoLi6OdhlSC8XFxcTHx9fb9hTQwrBQJ6e6OEVEJFJat27NqlWrKCoqUktaI+aco7y8nJycHFauXEmrVq3qbds6d1EYgapBAmpCExGRCElJSQFg9erVlJeXR7ka2ZXY2FgSEhLo1KnT5vOI1st2621Le6kt86BFtw4REdm3pKSkbA5qsu9RF2cYW071pIQmIiIikaGAFsbmMQLKZyIiIhIhCmhh6GTpIiIiEmkKaGFokICIiIhEmgJaGFtO9RTdOkRERGTf0agCmpk1NbPFZubM7Nlo1wPV50FTQhMREZHIaFQBDfgjkB7tIqrb3IIW3TJERERkH9JoApqZ9QZuA/4Q7Vqq0yABERERibRGEdDMLAYYCXwGvB/lcrayZZoNJTQRERGJjMZyJoHbgQOB86JdyLYCVS1oUa5DRERE9h1Rb0Ezsy7Aw8AfnXNLo1zOdrac6kkRTURERCIj6gENeBFYDDxR0xXM7Dozm2Zm07KyshquMqrNg6Z8JiIiIhES1YBmZpcBpwA3OufKa7qec26Ec66Pc65PenpDD/rUIAERERGJrKgdg2Zm8fhWs9HAWjPrHrqrfeiyeei2Dc653GjUCOriFBERkciLZgtaIn7OsyHAwmr/vgrdf1no+q+iUVyVqkECIiIiIpESzVGchcAFO7g9HXgeP+XGv4CfIlnUtrZMsxHNKkRERGRfErWAFjrm7D/b3m5mnUP/zXTObXd/pKmLU0RERCKtMYzibNQ0D5qIiIhEWmOZqHaz0FxojefAr83TbCiiiYiISGSoBS2Mqha0oPKZiIiIRIgCWhhbmvKU0ERERCQyFNDC2DJIILp1iIiIyL5DAS2MzYMEFNBEREQkQhTQwtgyD5oSmoiIiESGAlo46uIUERGRCFNAC2PLPGhKaCIiIhIZCmhhbB7FqXwmIiIiEaKAFoZpHjQRERGJMAW0MAJVZxJQE5qIiIhEiAJaGLb5VE/RrUNERET2HQpoYWzp4lRCExERkchQQAtj8zxoUa1CRERE9iUKaGHY5j7O6NYhIiIi+w4FtDACmyeqVUITERGRyFBAC8PQuThFREQkshTQwjC1oImIiEiEKaCFoUPQREREJNIU0MJQF6eIiIhEmgJaGFsmqlVCExERkchQQAsjEEpoimciIiISKQpoYehUTyIiIhJpCmhhaB40ERERiTQFtLDUxSkiIiKRpYAWhgYJiIiISKQpoIWxeZCA8pmIiIhEiAJaGKEGNJw6OUVERCRCFNDC2Hyqp2B06xAREZF9hwJaGJoHTURERCJNAa2GNEhAREREIkUBLQxNVCsiIiKRFtWAZmYHmNnrZjbPzPLMrMjM5pvZE2bWNpq1VdnSxamEJiIiIpERG+XH7wC0BT4AVgIVwCHAdcBQMzvcObc+ivWpBU1EREQiLqoBzTk3Dhi37e1m9jXwDnAV8FiEy9pKVQtaUAFNREREIqTWXZxmdrSZXbvNbeeY2SwzW2Vmf66HupaFLlvUw7Z2i+ZBExERkUiryzFofwDOrrpiZp2AN4EMIA+428yurs0GzSzBzNLMrIOZnQr8I3TX6DrUV7/UxSkiIiIRVpeAdhjwTbXrQ/Ex5nDn3EHA5/hjyGrjV0AWsAIYA6QClznnJtahvnq15VRPSmgiIiISGXU5Bq0VsK7a9cHA1865VaHrHwOP1HKbHwLzgWbAEfgWurSdLWxm1xEKgZ06darlQ9XOli5OERERkcioS0DLBdoAmFk8cAxQ/bgzByTWZoPOuZX4UZwAH5rZe8BUM2vqnBu+g+VHACMA+vTp06DZyXSydBEREYmwunRxzgR+ZWZHAg8ACfhuySpd2LqFrdaccz8BM4Cbdmc79SFQdS5OJTQRERGJkLq0oD2CP87se3wP4Fjn3LRq958JTKmH2hKBlvWwnd1iqAVNREREIqvWAc05N8nMeuOPPcsD3qq6z8xa4cPbBzXZlpllOOfW7uD2E4FewFe1ra/eqQVNREREIqxOE9U6534Gft7B7dnA7bXY1AuhUzp9iZ/7LAE4Ej8ydBNwR13qq09VXZwiIiIikVLrgGZmMUC8c66o2m2pwDB8l+SbzrnZNdzcm8AVwOVAOn6AwTL8PGh/c84tr2199U2DBERERCTS6tKC9g/8yM1eAGYWh58X7aDQ/b81s2OdczPDbcg59w7+lE6NlgYJiIiISKTVZRTn8fi5zqqcjw9nNwP98CM479n90hqHzYMEolyHiIiI7Dvq0oLWFlhS7foQYI5z7gUAMxsBXF8PtTUKplM9iYiISITVpQXNgJhq1wcC46tdXwO03o2aGhVTF6eIiIhEWF0C2hL8FBuY2XH4FrXqAa0dfvqNvYKhYZwiIiISWXXp4nwJeMLMZgPtgfVsfSaBvvjzau4VtnRxqgVNREREIqMuLWhPAX8ASvGnY/pl1ZQboYlqjwFG11uFURYIJbSg8pmIiIhESF3OJODwp3t6ZAf3ZbMXHX8Gm08koEECIiIiEjF1aUHbipmlmVlafRTTGGmQgIiIiERanQKambUzs1fMLBc/79k6M9toZi+bWfv6LTG6Np9JIMp1iIiIyL6jLqd66gRMBjKAmcCc0F0H4U/bdIqZHeOcW1FvVUaZGerjFBERkYipyyjOR4AWwJnOua0GA5jZ6cD7oWWu2u3qGomAmQYJiIiISMTUpYvzVOD5bcMZgHPuU+AF4LTdLawxMcCpk1NEREQipC4BrQWwcBf3LwRS61ZO42SmHk4RERGJnLoEtJX40zvtzIDQMnsNUxeniIiIRFBdAtq7wAVmNtzMmlfdaGYpZvZn4ELg7foqsDFQF6eIiIhEUl0HCfQH7gbuNLPVodvb4U+i/i3wp/opr3HwozijXYWIiIjsK2rdghY6rdNA4HpgLFAY+jcGuA440TlXXI81Rp0fxamEJiIiIpFRlxY0nHMVwMjQv72epkETERGRSAob0Mzsirps2Dn3al3Wa4wCZurhFBERkYipSQvay/gjsCzMctU5YK8JaJjOxSkiIiKRU5OAdmKDV9HIqYtTREREIilsQHPOTYhEIY1ZIGA4JTQRERGJkLrMg7bP0SwbIiIiEkkKaDVgZuriFBERkYhRQKuBgAYJiIiISAQpoNWIptkQERGRyFFAqwEzjeIUERGRyFFAq4GAoVGcIiIiEjEKaDVgaJCAiIiIRI4CWg0EDJyOQhMREZEIUUCrATMjqHwmIiIiERLVgGZmPczsj2Y22cyyzGyTmc00s/vMLCmatW1LXZwiIiISKdFuQbsGuB3IBP4I3AUsAP4ETDKzxCjWtlkgoEECIiIiEjk1OVl6Q/oPMNw5l1ftthfNbCFwHzAMeDYqlVVjmgdNREREIiiqLWjOuWnbhLMqb4cue0Wynp0xTbMhIiIiERTtLs6d6RC6XBfVKkICGiQgIiIiEdToApqZxQAPABXAGztZ5jozm2Zm07Kyshq+JlAXp4iIiERMowtowJPAscCDzrkFO1rAOTfCOdfHOdcnPT294StSF6eIiIhEUKMKaGb2CPBrYIRzbni066kSMJ1JQERERCKn0QQ0M3sIuB94CbghutVszXdxKqGJiIhIZDSKgBYKZ38AXgF+5RpZf6Ja0ERERCSSoh7QzOxBfDh7DbjGOReMcknbMYOgEpqIiIhESFQnqjWzm4GHgeXAF8AlZlZ9kXXOubHRqG1bymciIiISKdE+k8BRoctO+O7NbU0Aoh7QAqYzCYiIiEjkRPtMAlc552wX/wZGs74qOpOAiIiIRFLUj0HbE/iAFu0qREREZF+hgFYD/lRPSmgiIiISGQpoNaBTPYmIiEgkKaDVhOZBExERkQhSQKuBgOZBExERkQhSQKsBC7+IiIiISL1RQKsBnepJREREIkkBrQZ0qicRERGJJAW0GjDUgiYiIiKRo4BWA2bgNNGGiIiIRIgCWg34Ls5oVyEiIiL7CgW0GjBMM9WKiIhIxCig1UAgoEECIiIiEjkKaDVgmBrQREREJGIU0GrADJxa0ERERCRCFNBqwMw0SEBEREQiRgGtBgyNERAREZHIUUCrgYCBZqoVERGRSFFACyc7k07li9XFKSIiIhGjgBbOmPsYlvWYziQgIiIiEaOAFk5CComuUD2cIiIiEjEKaOHEp9A0WKguThEREYkYBbRwElJICBbigsFoVyIiIiL7CAW0cOJTiCFIAiXRrkRERET2EQpo4SSkABBfURDlQkRERGRfoYAWTrwPaMGS/CgXIiIiIvsKBbRwEpoD4ErydD5OERERiQgFtHBCLWhJroj8koooFyMiIiL7AgW0cEItaCkUsrGwLMrFiIiIyL5AAS2c0CCBZCsmp0gBTURERBpeVAOamf3ezN41s8Vm5sxsaTTr2aFQF2cyRWpBExERkYiIjfLj/xnIAX4AUqNcy441ScJZDMlWRI4CmoiIiERAtANaN+fcYgAzmw00i3I92zOD+GSSy4vYqC5OERERiYCodnFWhbNGLyGF1EAxOYXl0a5ERERE9gEaJFADFt+cFjElOgZNREREIkIBrSaqWtDUxSmEYnK3AAAgAElEQVQiIiIRsEcGNDO7zsymmdm0rKyshn/A+BRSAsVqQRMREZGI2CMDmnNuhHOuj3OuT3p6esM/YFIaLYJ5ZBWUNvxjiYiIyD5vjwxoEZfcluTKjazZWEBpRWW0qxEREZG9nAJaTSRnECBIajCP5dlF0a5GRERE9nIKaDWR3BaANraRzKyCKBcjIiIie7uoTlRrZpcD+4WupgNNzOz+0PVlzrnXolPZNpIzAMiwHDKzCqNcjIiIiOzton0mgWHACdvc9kjocgLQSAKab0Hbv2kBi9arBU1EREQaVlQDmnNuYDQfv8aS0sEC9GhawEQFNBEREWlgOgatJmJioVkbusRvYv7afApKK6JdkYiIiOzFFNBqKjmDTnF5lFc6pizOjnY1IiIishdTQKup5LY0L1tHQlyAiQs3RLsaERER2YspoNVU+yMJbFjAGZ0q+WaRApqIiIg0HAW0mjroFwD8In46mVkFFOo4NBEREWkgCmg1ldYd2vTi0PyvcA7mrcmPdkUiIiKyl1JAq42DziF1ww+0IYc5qxXQREREpGEooNVGqJvz3MQfmLM6b/e2FayEpd/UQ1EiIiKyt1FAq430HpDek3OaTN39FrQFn8LLQ2Dd3PqpTURERPYaCmi11WMw+5fNJXPNBtbmldR9O5vW+Mu8FfVTl4iIiOw1FNBqq+PRxLhKDmYJ//1pNQC5RWXMWlnLLs+i0GS3m9bWc4EiIiKyp1NAq60ORwEwpMUK/j15GcvnTeWjlx7j3Be+ZX1+LVrUCv1cav/5+gfyisobolIRERHZQymg1Vaz1pC6H2e1WkVOYRkr37yNK7P+Ru/gXP49edlWizrndj5fWqgFrSh7FTNWbGzoqkVERGQPooBWFx37kp4zg/HD9qNfYDYAf2n2Ji9+ncmVo77nqS8WUlhawVtTV9D3z+PILijdfhtFvgWtteWyLLsoktWLiIhII6eAVhf7nwKF62n15V04C1DW77d0KV/Ebw4uYV1+CU+O+5kzn/mGd6etoKC0grFz122/jaIcAFrbRpZmF0Z4B0RERKQxU0Cri/1PhUAsLPkaO+gcmvS7CSzAr9vM5bPbBjDy8j4s2VDID8tzAfh09g4GAhTWoAWtMBueOwbWzm6oPREREZFGSAGtLhJTocsJgMEJ90CzdOh8PMz4N8x8g5Pj5/Bsy7c5wJbzZMv3mZy5no9mruK378wkr7gcnMOFjkFLJ5elGwp2/Dirf4CsebDk68jtm4iIiERdbLQL2GOd+gisvwRaH+ivD7gLPrwJPrwRgDOBgU0n0Kwol+lxaSx890M+rDyHTSUVPP2LbiQGy1ntWtLOcsjfmEVlzlJi3r8Wzh8FqR39NrMzQ5eLIr9/IiIiEjUKaHXV5mD/r0qXAXDbLJjyD1gyAbIX0WzDzwD8kX9gcY7jOsSSuOh7rn3qev4N/Ow60c5yaBdcS86UN0lf+T2FM97lx05X0Ge/ljTJqQpoCyO/fyIiIhI1Cmj1yQyOucH/WzgWvnsWElKxuR8CxrHr3oQAnOF8l2VulyEEVy/iNvchK6cUkg78OP4/XFJ2AAe3S+GD5J9pAlta0nYhp7CM1MQ4AgFryD0UERGRCNAxaA1l/1Pgio9g4O+h7w3Q7xZ/u8VwYfxkAAYNOIHACXdxkk3nCOZT6OI5OmYBT5zdlYXrCshdOd+vk7+KC58dx/RlOds9jCsvYd1fj+ThPz/MXz+bH6m9ExERkQakgNbQWh8Ip/8VTrgbhr4Bvc4ltngDNE0juX1POPbX0PsKwIg/41FiXQXn/nAFv+1ttKpYx1LaARDIWcxv3pzJmrxiSkrLWPve3Xz8xVfMnDyWNsWLGNZkLC99u5SVGzWnmoiIyJ5OXZyREt8MDhwCwUqY/T6cNxISUvx9Zz8Dp/+N2LgEaNEJ3ruW68ruJGCO1CPOgRkv8NTBCxnyQyrf/v1ClgQzuCvuHZpWTuFbunBEDBzqFtDB1vPkFwv5+wWHRXdfRUREZLeYcy7aNeyWPn36uGnTpkW7jJpzDkry/FQdOzP7PfjPNdB1IFz0b/js9zDjNSqS2xO7adV2i2+IzSCtYi3fZlzO5ctO59NbB3BARnLYUv7y6XySmsRwy6D9674/IiIiUmNmNt051yfccurijDSzXYczgF7nwW/nw+UfQnwynPUUnHAPscXZ0PMsv8wRl+GaZQAQ7HU+HHIh/bLeplf8en733k8U5+dAMLjThyirCPLKpKU88+Wi2p3kXURERBqcWtD2JMFKsADM/Qi6nbj5bAbs1w/KS+C5oyiIa8UFG67ljSaPMjvxKAoCyaxJOZTUoy9m4AGtaZnUBICpSzbw1si/sZpWHDHgbH532oG1qyXrZ1gzEw69sAF2VEREZO9U0xY0BbS9ybJJ8NovcRVlGFtaz8qJ4a6y60mLr+TovsdzRL9TyH3lEvbP/pLsmDROrnyGib8/lWbxtTgk8cObYOYbcPfS8C2CEh1T/wnJ7eDAMyLzeOUlsPQb2P/kyDyeiMgeqKYBTYME9ib79YOrP8U+udV3k879CNofSeziCTyZ/Tw4qPxuBJO+PZj+MbOZEnc0fcu/p3fZNB7+uD1tmyeQkhhH1/QkEmJj6Nu1FTE7m1dt7U+AY/b34+h1wnkR3U2poa/+Aq32j1xA++kt+ORW+PU0SNNxjSIiu0MBbW/TvjfcMNH///jbALDKcljxPa5JU3K/ep6jF49mbsogAkNegA/689fi1/j+p4kcGljMJpfIB5XH83mwD4ltevBSr5lU5K2joN/v6NgyicKyClonBmC9n3Nt/NiPyWt/Asd1TyMYdGQVlNImJaFWJa/KLeYPr4zmrgtP4YC2KfX6dOyzSjdBYRausgxXGSQQE4HDTbMWhC7nK6BFUkUpWAzE7AMf55vWURGbiMUn7/zHo8heQoME9gUxcdD5OKzdEbS6ZCTx963koN+8z1Hd2sAFL9OqTUcGt1xL24OOp0ubFtwb9ybj4+/i/zbeTMY3D9Bh1rOse/5MVv/5cL7++1AmTBwPwXKCzjg6sIDf/ecn1q1YyKQXbuTDv13H4lXrtjx23ir49imoLPfXSzfBpnW4jcs2z9m2dPST/HPjNcx9677a71tFGbxzJSz4tB6eqEZk/Tx/zGFd5SwBwEryeOzdcXXbRnZm7Z7XqnPGhk5x1mhVlvvu2L3FqMHwv99Gu4qGF6yEkScy/qlh/OXTeRF5yOKySqYt3X6CcKkF52DT2t37PKtvhRsg88toVxGWAtq+yKr98tyvH3bdl8TcPouYi14h4eaJcPsc7Nib6NhxP2b2uJWNGcdxXOw8gknpnG/j6f/VRQB8F9uHo2IWcmzxBLL+NZSj17/DrwIfE/fKaayYP5XshVMoeGsYjH2Q9RNGUvn5Q7jhHeHxHthTh/Le4zcz7X8j6fvz38lzTfll3qtseqIPfPecD17VVAYdT32xkHU/fuGnKaky6WmY+6EPgVXHUwYrt/y/mmDQEQzu3jGX05dt5MkvGjiAZP0Mzx8L34+o+zZyFm/+74bFM+HHt2Hux7XbxhcPwVuXQsH6mi2/wZ8zdubMaZRW1PLDeMnE7f7mAOSt9IFqzU9QWlC7be7MB9fDPwZAWWH9bC+asjNh9Qz/Hqj6ERRNleWwctoO33+7bdV0yF9Fr+JpfJe5of63vwOvT1nG+S9+x6rc4rpvJG8lFG/0r7n6CgWTnoVZ/6n58qtn+kNe6kveSv/ZkL96x4+14FP//irJgxED4fED/Gfa+gY+203xRl9bOJ/cCq+d64Njlfw18P3IxvE+Col6QDOzgJndbmbzzazEzFaY2eNmlhTt2vZZzTvA4EdJ+tV/OfySP9LiVx8Q+7uFHPC78RT3uYmAOYJNUuhz6xsE2h3G3+1JerGI55rfwbsHPknz0rV0fOtkWr1+Ks3WfEeuSyJtwr3ETPo/Pqzsx3MJ1/NhZT9ujX2fPlPvZHawMyMPfZtXk65mQW4AxtxLyUvnwJQRsHYWzPg3K9+5i/Lxf6XNB+fBGxf50atvXw5f/gmaNIPl38Ezvf2Hxv/1Iv/9W8krrvZGy1rAqCfv5/HXdvKh9uWjfrvVgs12ZrxOkzfP5+0vJrNw3SZ/W/5q/6YeP9x/AP33tzsOGhuX+vOzrp6x8+0Hg/4DfNY7gIMfXq3ZF12wEt671oewcX/0lxuXbL67e9GPuE9uxX10M3m52f5G53a97coKWDwBXCUvPPcYleGCbUUZ5C7z5WT9zLeLavEFumIqvHImTH5+69vXzYGnDofP7sGNPBH35SM132aVj38Do3+35Xp5McwfDRsWwNg/+O7BomotJJvW+cE2VUryYNl3tX9c8K+NV86GJw72LaINoaqFsyQPlk/e9bKf3+/fM7tr/v9g1OlbP2/gn6dXfwH/HAQLRtdum5UVMON12Lhs58uEttnWcihZn0lF5c6nESJYueP3YW2sn8+Jk67kqya3M2/RYl/j6hlbv28yx8MrZ+38fMmLJ8D/9fKt/Gt+hP/d4V9z4H/4LBoHa2fXPNA659/fn99H+ce3M3H2kh0v9+nd8ObF/v+lm+CtS/xnRNWPkuxMv50dPW4w6N8HleX+dbujZaaNgvn/hbEP+uuV5X7Q2MTHYcQJ8OZQeOZIP4fnmpnQ/w4oXA+f3eM/06v+NiunQ0m+fx3nLq/Zc1ClKAcKs7eu+9VfwHPH7Pj9NuUfMOJE/5jz/ws4+PmzLfdP+KuvN3/7uUajJeqjOM3sKeA3wAfAp0BP4BZgInCyc24X70KN4oyKjUv9h1Vadygr8r/eS/Kh7/U4YP6cGZTP+S8bYlqTQAlTN6Vxce6LfJP6S6amnMJ7M1Zx9+AenBQ/n399NoV3i47g7ZtPpEtaEg99PIeYWW/zaMxI4m1LwApiBHCscmm0t9CXf3wK7ujrWJkxiI7vnk4wNgGrLMMF4ghUlrI6kEFMp77Ycb8h7Z2zCZQXUuriKDxrBC2LFvsvta4D/YfWu1eBq/SjHm+eAjNe87/YT7gbktKhJA/3Qj+svIg1riUfHf06N5x+DLw8BJb7L/TCtMNI2vAjJScPJ6F5a5j+sp/DbvUMeG/Ylufvgleg8/GQlLbltooy/+E17V8AOIvBXCXFpz5G4lFXQtY8iImH1j19GC0vgv2Og7hE/8Hz6e8gsSUU50AgFpfWg43rV1FKHC1d3ubn8uOk8zl70EAY/2f/uKf9GQ7+5fZ/4+WTYdRgyohlabANxWeN4LBu7aFlFwgGyfxxIj/NnMrZJ/ajsv3RNMnNhOeOpjDQjIrKIE8eOZY/nN1r623mr4GFn0P6AYBBhz4QiPFfJlNehJZd4dfTIRDwX2KvnA0rtoSO4rgWJN6zEKb+CzIOgc7Hbb39rAW+6+Knt6BNL+hxGjx1mG8xvmW63/6Cz+DNi1ib1JPWhfPZ1KwLgdJNJN8505/t49/nw6KxbOj3AGmn3gnvXg1z3vdfMCc9ADNf9/U2bQlXfAzNWkOTbX5LBiv9fn1yq//Sshg49AJ/xpAqOYth8otwyAX+eVg4FjoevesR0aUFENfUPz8leTDmXv/FltDctxrENPGnjTttuP/CtICvA/wX2RM9obIUrvsK2h3hb1/ytf/CTEqHOR9Ah6PguNugsgziqh1LOvs9GH2Xfw2W5EF5IZz6KPT7tb9/5hvw4Y3+x5LFQNcBfpLtHSneCOMegaOv8z8G373SB4aNSyCptT+HcZuDQq+Z1dC0lQ8Jzx9DUWk5TYtW8vvyYQy79WG6tw5NyL1wLMSnQKe+fvuvnAWxCXDN5/75AshdASW5/rUDPlB+/Zh/ri79j99f53yIj0uEl89k0/IZJAWLmNLuUo5tF+vf0/sPhqN+5c8E8/KZECyHtofBNWP86/rz+/3nR/eT/Y+Mqh9LcU39+7b7ydAsA35803/mAHQ7ye9rUY7fbkJz6Hqin/eyohRc0L8XfnwLsubjUvfDcpcxKm4oVx+ejCWl+eepcAMccLpvtcJB7yt9CMwPtSpd9Lo/o83IE/3n0sDfw/G3Q2y8f92u/cm3nC+e4I8j3fAzdDoW9j/V/70yv4TCLJj4hL+sLIWhb8KKKfDtk/4xup8Cfa/3P1bzlvv1r/kMvn0axj7glznicuhzNYwc5N+r62b55+DyD3b++t/qvbAJXjjOX57znP8cn/sRfHiD/7untIcbvoEmTf3yleXw5CGwaY1/noKV/n2bcQhc8nao1+IYOGoYnPG3mtWwG/aIaTbM7GBgFvCBc+68arffAjwNXOqce2NX21BA2/OUVwaJCx207pyjoLSC5IS4zfevzi3m9W/n8+XUOfQun86Pwa4sd60Z3mkqT6w5hKSKPLonFZPQ9Ti+X1vJovUFXBPzKT8Fu5CQ3Io8kvhr6aPEujJ6BPyvoaLYVC4u/C0Pxb3KEYFF29VURALvdnmYK5bcQ2nrw0hYP3PzfUGLpTLQBMy4segGnmnyDIWWRKukeKxgLZzyCMHO/Rny7ibuy76HfjHzCVCJw6BZayxYgWvRmQ9b30yvH/5Al7gcYisK/YdeSnto1gZm/Nt/iLY9HNbMZMVB11E++2O6BtbimrbCikK/FNMP9AfhA7TsRmWbXgTmf4IlpUPBOlxME6xZBuQtZ7VrSWbv+zn8h/tYmdSLeZviOTfmG79ux77+g3/NTOg2yH9Q7dfPz62XfiB8djdu/mjuLruGP8WOoomF5uA7dCismrbVcWarSKdll94kLhnDmEB/Bgcn8lz8tdx86QWQkwnJbf3lZ7/3X/xVOvWDE+6CD27EVZZixRvhsEugywDfvbv6BzjwTJj/XwpdPElWSmXHY4lZ8R1gkNoROh7jv8SWfgNTR/ovMvD3dzvJf6HExPn963QsLJmAy1nCwJLH+ch+S6r5FoWitn1p2qY7zHydDdaSNJfDpqNvJ/n7JyG1k28dPOQC303c9lC//xVlUFHMD/Sk80nX0LLzof7LbdUPMOBOmPAYHHml3+ef3vUBrd3hMOkZ/0VbWeqf0w5H+S+41gf7gNHuCD9BNfhurOQM/6Mo80vIOBT63QLjH/UtDh2P8V90ucv9D6U1P/kvuTH3+sc94jLfQrlxKayfQ0UgntikltD+SP+lVrUc+NdhwTr/I6WsEC4Y5V8bucvgxf6Qup//UZa7AipKfBjo0Md/wU79J7TqRu55b9Hk6+E0/fFlOP0xSGnnW8UOPMOH8+mvQGm+D6jtjvA/Mr571oeR/U/xz40L+oCU3A5WTvW1pnaEWe/y8cFP0nv2n0gnl7yMY2l9zFDftf7tk5DYAvpc4x+jKPQj7sAzfQhs1d23LpcX+eevKMeHyqatoGAtHHOTPy/yV8Php7ehc3/IHMcjlVdyCAs5O+Y7Ajj/nK36we9DQnPKYpJ4svIC7ip5Gmt3hH+tL/iff9yl3/gfB10H+vB79PU+9Iy514fYwy/xP45WToUvH4EWXaBLf/9jt2A9LPsW2Ob7ueMxcNhQfm49mA0jz6NfzNztP2Atxr9+zHxY3e84/zr45Db/mmt9MKyfA2k9/Os4saX/W6ya5sN3TBP/Hlz2nX/9LhrnW5zjm0NptcNLznoapr/kWwZdEA65EDod498nCSk++L99OQx5HLoP8j/m/3NNqLV3EqR2wuWtxKq3wVzyjt9e+94+RKW02xKoq1SWw/vX+dd7clvf4tWiMxTn+r/zoAfg1XP889m8g/9BvGQC/OdqaJIMZZv8D+f18/yPvb7X+/d1aT78eqr/0dXA9pSA9ifgPmCAc25itdsTgGxggnNul3MEKKDtvSqDjiUbCokJGEs2FNCvWxo5hWVMW7aRT35czYzlG+mW3owzD2tHRkoCGwvL+O+sNTjnuPGEbhSVVWKZY/lp6teMLj+S+HYHcWTbeHr/+AfyXBKvBU+jV0ohsZtWkpLWnndye3J5xXtcGTuGubY/rzS5mHZFc+nMGlraJl6sOJONTbvyj6PXU/jNixTEtSIzsB8Zp97BrNX5vDZ5GQNb5TE47x3WJ3ZhbGE3Hop9hV6Bpdyc8BfG5WZwStwsno95jKy2J9IiezqBYAXxFZtY0ewQ5nS/gdy2x1E8/S0+KjmcudmV9HM/8kDSR5R2OZnYpOZ0nfUUUxOPZ1HLAZyydiSuJJ+JscfyaYtL+GvWzXzrDuWztCt5fONveC94Ahfc9xqXPz+OuWsLKKEJl8aMY1DPNmw44BJwlZydNYL4peP9l1zVr3nAYYxNv5LrVpzKkHYFtMr5gbt6rKfZ4k8paXUQD646ih8qu3GwLeOCmK/oG7sQMnoxaOlljEx4hgPd9l3FGzOOI3jyw8TkrySxZD3xEx6F0jwcxm3uDq5uOZvDCiZi5YW+RWfIE2xo25+CZwbwsjuTqyrfo1Mgi8AxN/oRi7nLfYtYRTHOYpifcTbZ7QdSnJBBn+m/o0XxMh/eupzgj1Us3EBZYjrjWg7lxvmHMShuFm2C6zkuZi6DA1OJCfjX3KmVT/OoPc+xgTmUBRL5+ITRnLBqBOk/vwmtD2LV2W8z/4eJnLj+FT7KbschhVPoHvDH4rjkdtAsHVvzI655R3445W1mLVrG5XNvIKYs9OUW04Sigy8mePT1NPvxJZj+EhUHnEXM4nFYsMKHiCqJLX0rQXIG7oDTqZj5DnFludCsDe6Cl/kguxMLQt3tiRX53PzTecSVb4LYRN8iWJgFLbtSSYAx2a35qaITt2TMISl/sW8F63CUn5Jnw0IY/GcY/yjB2R9QSiyJ+UtwCalYsBKHY9ppn1DRfD+/C/M/4uipt1OZ0pGY/BWQ2ILxx/yLX40pZT+3itHJj5JQtnH7N3WbXn5/Oh/vWyMBd9jF2C9fJLuglOb5PxP72ln+CzdnMaT3hJXf+wAw4C5uWz+EZYtmc1bp//hF0mxalqzw2z3wTN8F6oK+5bTfLVT873fEbJiHWYxv5erY14eX5ZN8mOt8PEv7/YWYz39PxxXVjs/s3B/yV1HQ/ACOnHcR+yWWcEHwM64Y1Jv4424GHHz0a/jpLUa1e5g/Lt6fsxNm8H8J/ySmZCOceL//4VH1XirJo/z9G4k7+QGsdU/KiguIa5LAz1nFVAYdC9dv4tgWm0jL6MQ7P27g4HbNOaRDc7//a2f7FiEzaNXNtwIDo75Zwl/++yMnBWbQ/7ADuCT3RayyAo6+1rckH36xbxVaNxtOeoCsokoS/3sjzRa85wNv0zQY+roPLjP+7cNKx6Oh8wDoMoDKpNaUlZWRmBDvd2L6yzDhb3DyQ751c9kkOPIqHwAnPe3fr0ddu6XFKqSkvJJPZ6/hxa8Wc+2Arpx/ZAcoLSD49mVY/hr+XnkRPTaMZaI7jEcS3yKxfJvXjMX412gg1ofOihL/Ws1f6Ws56lrIHAcf3QIuSP6VX/DAxGIGr36e02J/IJC/0geuknxo1prgmU+R9+P/WN3nTlLcJhI/vY20VeN80Lv4Lf8DKgL2lIA2BjgZaOqcK93mvm+BHs659F1tQwFNwpm/Np+vFmTRt0tLDu+YyuhZa1maXUhBaQWzVuZxYEYy9w3piXOwLKeIbxZmMX/tJorLK2mdnMBlx3Ri4boC5qzO45zD29OxZVP+OXExb01dQcDg53UFmMGlfTvx+9N78sp3S/lpRR7dWzcjEDAy1+VSUmGceVhbDuuQyg0vT+Ln7KruW0fbuEJyXDKlFf69mBwfy6bSCu48tQdNm8Ty/FeZbCjwb49YKkhKTNzcCnlyzzZsKCiltKKSI1tVUBmXxLRVJcxemc0ve+/H8PMOZfaqPK4Y9T0Ht0thXX4JP6/b+mD75IRYOgay6RybQ88WjrTKdXyY3ZEpxR244MgOXH9CN4aO+I7conJiAmyu87zeHfj4x1UMPKA1Y+euw8z3EI24rDcfj/uKsnULyHTt6J5YRHywgNElh1BRbWafzslB+sfMZU55Bj9XZFBQWkFSTAUDUtaT0P4gluTB7FV5BJ3jqaFHMH7eOt6fuYr2qU1pkRRHSkIclUV5tC5fyUqXxozsLdtuQjmtLZeDD+zJ2k3llJQHiY8L8NNKH5L2a9WUR87pxbr8EhasyuHN7xZyRLMcYovWM/gXV7A8K5cp34wjN6YliyvSQvVCnx4d+GpBFhsKSslISWBtfgmdWiTSLm865zdfwKMbBxGMTeSGtguZHHMUE5b6Frp4K+f0lus5o9kCJif2Z9R832LcPDGOtkmwILucDslx9GibypEJKymucLRJCJKd1J1564rJLg6yJKeEwoI8Do9dTqcDj2BZUTyTF+fQJCYA5gfBHO7mcW6btcR2O4GFFRksXbOOLJdKwOCH5bkkJ8SSHB/L+d0dLSo3MMt8d3PrlAQS42LILizlwxmrCJbkc0bMFPrELKZ7C+PpyvP5asPWU+DEU0ZaanNO6ZFCZnYp3y/L59AOzUmIi2HSovX0SS3E5a6k1JowtMkkEnqeyur0/ljAmLMyj/1zJ/5/e3ceZUdVJ3D8+3tbv9f7lnSS7nRCyEKCmSRA2IWgiAMMOnqGVTxnQGRUQEUPc8YFUWF0jgyLBj0qMiCI5wjKMmQcwhoHUEkghMSELBA66SVJZ+m9+3W/5Td/3GryeLzudCDpV935fc6pU+lbtypV9/eW36uqe4uacB937DiWPgroiiepKAwzvTzM9vYE0SCkJMg55c1ESyp5prWYrbt7+PCsahKpNKsa9nF1XSOpcAktRXNZ0vE4YUmycdrl7O0Z4P/WvEEo1cfUyiIWVKXZEZtNZ1+CZF8nC2bWU1MW5c6nN9Pe08cXpu/ijMo2ejXKY+nTeb2pg4JQkE27urjh43O4dfkmiiJBplUVEQkF2La7k3+c2stvtsY4e24NqxraCGmC44v30FU6m6riApraeikuCLFxZxc7OuIcPaGIkmiYtU3tTCqN0tKxvydxZVGEaVWFvLa9nWBAOHpCEQERZteUMGdSCQNJ9/qND6RIKyxfv88vpj8AABNgSURBVJNEKk1tRYyX3tzLxBjMm1JKNFrIpLIopdEQybRSEAqyrrmDP21uJZbq4tzpwqxjT6CnP8Waxjb6k2nm15Uxe2IJoaAgIqx6ex+/W9VISpUFdWUoIMApR1dRURghEgrQ2tnPk+t3UhYLEw4KARFCwQBzaoopL4zQN5DisTXNtLT3kVYoLgjRO5DkhGmVFBYEeXHLHiqLIrR29fO9TxzLb1/eTtuu7ZxftIFZcxdRv/1RuqJTmBRop6a/gbAo4WQnGojQW1jLjtqPsyJ0Oo1tvaxr7qAs3sTi2kKe2FHG7q5+kmllUX0555Y28MkdP6Yo1cmyRXdz3xvKxp1d73odf+JD1SyYNoGBlPLW7m7+49PzCR3mYYnGSoK2DpioqjU5lj0EXAgUqOpA1rKrgasB6uvrj9+2bZgbS405jPqTKTa0dDKhpIC6isIDr4C7xPva9namVsYojYYpjLj7hNp7E+zu7mdGdRHrmjuYX1tGKBggnXYfHD0DKTr6EiysK6ckGkIEJLNHboaBZJpQQAh4Y0V1xROICK2dcdY0tjO9uoh0WnllWxs72vtIpJV93QM07O1BFeoqYnz9nDnMm+K+lBv29PDwq430J9JMqy5iSlmUJXMm0toVp6qogGVrW9jS2s1AMs2/neseG/by1n1s39fLK9tcErFkzkSa2/uIhAJ09iXYuruHnv4kjW293HTBsRSEAixfv5Otu3tY29RObUWME4+q5FOL6pg5sZhUWvnVC1vZuLOLjr4EHX0JigtCFIQCDKTSnDNvElXFEWLhIAvry7n9qc2s2NRKWWGEisIwiVSaU2ZUcerMaiaVRplSHgNcYvPYmmaWr9/J5LIYN13g7n+KJ9IUhALs7IyzqmEfy9buYE1jO5PLonzmpHqeWr+LQED44afn87Pn3+KvW/fy4VnV9Awk+fNbe+lPpLnitOmcN38yj6xuYmVDG+ua2ulPprn0xHpqSgvYvq+XnR1xZk4sobGtl7dau2lu7/OSpQHSqsyoLqKmNMqk0iinz6pmVUMbKza1EgsHueykej53+lGICAPJNHe/sJUH/rKNnZ1xYuEgcyeXEIsE2ba3l8XTK7l48VRuf3ozG1o6SaX1nUe/tXbFSaSUWDjImbMncNHiOjr6ErywZQ/PbXT/1zfOm0t1UYRkWukdSDGhJMLNy95g084uZtcUM726iBv/YR6xcJCfPLuFV7e1cemJ9SyqL+eG36/l1W37z47UlseoLIqwfV8vp8yoorokQm15IW+2dr+T/KZUUYV1ze10x5PMqimhM57gksVTOXf+ZG5ZtoH1LZ0kU0oilSaRTpNIKnt7+omGgpw7fxLzJpfy1IZdNLe7s1WRYICSaIh1zR2kFSaWFPDp4+r47cvb6IwnASiNhjj16Gp2dcUJBwL85qqTWN/SwSOrm2lu76M7nqSuIsbKhn109yd59Eun0R1PcvOyDUQjQdp7B9jd1U9teYyueJKZNcXMqSlh5dv7SKbTzJtcxpbWLk6eUUVdRYyKwgh3PfcmnfEEF50wlR0dfTTu6yORSvN6Uzt7uvd//Ym4ZKmyKMJXPjqLTx1Xx3MbW1mxsZW397r3U1NbH/FEioAIybQytdIlkeWxCA+/2khTWx8iMKemhEgowMYdXQxkdLgICFx4/FTKi8K8tq2dgnCArniSNY3t7/qMOWVGFSKQTCuq7jWxeVcXiZTLKT48q5qFU8s5YXolx0+r4NYnN7JxZxd7ewaYX1vG85ta+cxJ9dzw8WNQVf7W3MnXH17D5l3d1JbH6B1I0t6XGLL/RDAgTCmPUl9ZSEVhhJff3kdlYYT/vHABq7e38eu/NNDWM0B7XwLRNGkCHD2hiCtPP4poKMju7n664gnuefFt4gl3/DWlBTx2zWlMLosN8wn+wY2VBO0tIKyq9TmW3Q98FqhQ1fb3rOyxM2jGmPEokUoTEDnoAVlVlXgiTSQUOKh1B3vqHq4BYHsHkgREGEilKSkIDfnj4oNKpNIIDHsWJJ5I0dY7QEVhhGg4SDKVZk/3AEUFQYoioXd+2PhBPJEiFHDtFgoECAVk2B9n6bSSVkVEXFIa2t8Oqkpbb4KgCGWF7ixufzJFS3uctLpEqzQaZmKOwcb7kyn6k2kGku51OZjcZ1JV+pNpkmk94KMD02nN2c7q7Xvm/nbHkyhKWiGtbrikiaVRymLhnOtlSqX1nR79ufY57S0PBeVd90IfTmPlUU+9wFB35EUz6hhjzBEl/D4vs4gIMe+s7ME43CPzF0bc1000fPD7djBG0m7RcPBdZ0lCwQCTyg7uCSijZbC9RnrZLRAQArhYZsdUciRWBaEgR1UfeFSrglCQgtDwsROREcd3qCQ4M8ka3N9cidVw62UKBnInk5n7UTGC7edDvsdBawGqRaQgx7JaYE/25U1jjDHGmPEu3wnaKm8fTsws9HpxLgTs2qUxxhhjjjj5TtB+hxvo5atZ5Z8HCoEHR32PjDHGGGPyLK/3oKnqOhH5KXCtiDwC/BH3JIEvA38Chh2k1hhjjDFmPMp3JwFwZ88acMNmnA/sAZYC3znQY56MMcYYY8ajvCdoqpoCbvMmY4wxxpgjXr7vQTPGGGOMMVksQTPGGGOM8RlL0IwxxhhjfMYSNGOMMcYYn8nrszgPBRHZDRzup6VX43qXGn+xuPiPxcSfLC7+ZHHxn9GIyTRVnXCgSmM+QRsNIvLKSB5sakaXxcV/LCb+ZHHxJ4uL//gpJnaJ0xhjjDHGZyxBM8YYY4zxGUvQRuaX+d4Bk5PFxX8sJv5kcfEni4v/+CYmdg+aMcYYY4zP2Bk0Y4wxxhifsQTNGGOMMcZnLEEbgogEROR6EdkoInERaRSR20SkKN/7Np6IyDdE5GER2SoiKiINB6h/kog8IyJdItIpIk+KyMIh6k4RkftFZLeI9InIKyJy4WE5kHFERGaLyPdF5K9e23WJyBoR+Vau17+IzBGRx0SkTUR6ROQFEfnIENsuE5GlItLsva/Wi8gXRUQO/5GNXV4bPygib4hIh4j0ep9Nt4vI5CHqW0zyQEQKMz7P7sqx3GIzCrz2zzV156jry5iEDvUGx5E7gC8DjwK3AXO9vxeJyNmqms7nzo0jPwD2AauB8uEqisjJwAqgGfiOV3wt8IKInKqq6zLqVgIvAhOB24Em4DLgIRG5UlXvPcTHMZ5cCVwD/DfwIJAAzgJuAS4SkZNVtQ9ARI4G/gwkgR8BHcDngeUicq6qPjO4URGJAE8Di4ClwBvAucDPgBrgu6NxcGNUHTAZ93nUhGvv+cDVwCUislBVW8Fi4gPfB3IOQmqxGXUv8N6b/hOZf/g6JqpqU9YEHAukgT9klV8HKHBZvvdxvEzAjIx//w1oGKbuSqATqM0oq/XKnsqq+yMvVhdklAW9bewFivN97H6dgBOAshzlt3htem1G2UNACliYUVaMe7rHJryOSF75l7z1r8va7h+AAdzo2nk//rE0ARd6bfqvFpP8T8BxuC/6r3ntelfWcovN6MVCgftGUM+3MbFLnLldCghwZ1b53UAvcPmo79E4papbR1JPRGYCi4GHVbU5Y/1m4GHgbBGZlLHKZcBbqvpERt0U7ldPJXDeIdj9cUlVX1HVjhyLfufNPwTgXe78BLBCVddkrN8N/AqYjYvZoMtw75+7s7Z7JxAGLj4kB3BkGXzMXQVYTPJJRIK4dnwSeCTHcotNHohIRESKh1jm65hYgpbbYtwZtJWZhaoaB9bw7oCZ0THY5n/JseyvuIT6eADvnpxarzxX3cztmZGr8+a7vPnfAQUMHRPw2llEArizC69576NMK3G/Si0mByAiURGpFpE6ETkH+IW36I/e3GKSP9cDx+Buu8jFYjP6/gmXUHWJSKt371hZxnJfx8TuQcttCrBHVftzLGsGThWRiKoOjPJ+HcmmePPmHMsGy2rfR10zAt7ZgRtxl29+6xUfTDtXALFcdVW1X0T2YDEZiatwZ4EHNQCXq+oL3t8WkzwQkaOA7wHfV9UGEZmeo5rFZnStxF1deRMoxV01uRY407tnuRufx8QStNwKgVzJGUA8o44laKOn0Jvniks8q87B1DUjcydwCvBNVd3klR2qmAzWt5gc2GPARtw9Motwl2eqM5ZbTPLj58BWXIekoVhsRpGqnpRVdL+IrAX+HfiKN/d1TCxBy60X1/svl2hGHTN6Btu7IMey7JgcTF1zACJyM+6X5y9V9YcZiw5VTAbrW0wOQFWbcL04AR4TkT8Aq0Sk0IuNxWSUicjlwMeAM1Q1MUxVi03+3QrcBJyPS9B8HRO7By23FqBaRHIFohZ3+dPOno2uFm+e6xTyYFnz+6hrhiEi3wW+DdwLfCFr8cG0cxvQl6uu9z6rxmJy0FR1LfAarncZWExGlddOt+PuAdwpIjO9Dk3TvCplXlk5Fpu88xLoFvafdfZ1TCxBy20Vrm1OzCwUkSiwEHglHzt1hFvlzU/Jsexk3A2arwKo6g7cG+XkIeqCxfCAvOTsJuDXwFXq9SfPsA53un+omIDXzurGDVyNG0cw+4fPibhOHhaT9yeG65kMFpPRFsONeXY+sCVjWuEtv9z7+yosNnnnfYfXsb+jk79jku+xSvw44QaAHG4ctMvzvY/jceLA46Ctwo15NiWjbIpX9kxW3VsZehy0NqAk38fr5wk3ELAC9wOBYeo9jBtDaEFG2eAYQpt59xhC1zD0GEIJYHq+j9uvEzBpiPKzvPZ/1mKSl7iEcT0Fs6cveu36v97fsy02oxqXqiHKB78XMscN9G1MxNu4ySIiS3H33TyKO309+CSBl4CPqD1J4JAQkc+y/3LAdUAE9+QGgG2q+kBG3VOB53H34CzNWKcGOE1VX8+oW4U7o1aFuwTRjBvfbgnubNA9h+mQxjwRuQa4C9iO67mZ/VrfpapPe3Vn4pLeBO7pG524UbjnA+er6vKM7UZwI3YvAH6CG4X7POBTwC2qeuNhPKwxTUQexT1J4DncF0cUN6zMJbj7XpaoN46TxST/vF6cbwM/VdVrM8otNqNARO7AnQF7Hvc5Voxru7OAl4GzdP/TUPwbk3xnun6dcGdbvo4bSbgf9wV/OzYC/aFu5xW4XyS5phU56p8CPAt0A13AcuC4IbZdCzwA7MH1sFkNXJzvY/b7BNw3TEzeExfcj5fHgXZcsvAicPYQ2y7HJX8t3vtqA+6HkBzu4xrLE3ARsAxo9F7LfbjenEuB+hz1LSb5jdd0cjxJwGIzau3/Se+7odl7v/TgxjD9JhAdKzGxM2jGGGOMMT5jnQSMMcYYY3zGEjRjjDHGGJ+xBM0YY4wxxmcsQTPGGGOM8RlL0IwxxhhjfMYSNGOMMcYYn7EEzRhjjDHGZyxBM8aYw0REGkRkRb73wxgz9liCZowxxhjjM5agGWOMMcb4jCVoxhhjjDE+YwmaMWZMEZECEfmmiKwXkbiItIvIEyKyKKveEhFREflnEblORDZ79TeLyHVDbPsMEXlaRDpEpE9EVovI54aoO1NE7hWRJhEZEJEWEXlcRI7PUfcYEfkfEenytv17EZl0aFrEGDMehfK9A8YYM1IiEgaeBE4FHgDuAsqAzwMvicgZqvpK1mrXAZOAXwBdwKXAT0SkUlW/l7HtC4BHgZ3AbV7dS4BficgMVf1WRt0TgGeBMHAP8DegEjjT27dXM/7/WmCFt+0bgAXAvwClwDkfrEWMMeOVqGq+98EYY0ZERK4Hbgf+XlWXZ5SX4pKkraq6xCtbAjwPdANzVbXJK48ALwKLgKNUtUlEgsBWXLI3T1VbMuo+D5wMHKOqW0REgHXATOBEVV2btY8BVU17/24ApgEXq+pDGXV+CnzJ2+amQ9dCxpjxwi5xGmPGksuBjcCrIlI9OAER4GngdBGJZa3z4GByBqCqA8AduCsIF3jFxwP1wH8NJmcZdX+E+6z8pFe8EDgWuDc7OfPWSWcVtWQmZ57nvPmsERyzMeYIZJc4jTFjyVwgBuwepk410Jjx9xs56mzw5jO8+VHefH2Ouuuz6g4mVa8Nu6f7bc1RttebV41wG8aYI4wlaMaYsWTw8uLXhqkzXPKWD6lhlsmo7YUxZkyxBM0YM5ZsASYAz+W4lDiUuTnK5nnzrVnzY0dQd7M3XzjC/98YYw6a3YNmjBlL7sf1yMx5Bk1EanIUf0ZE6jLqRIDrcWe2lnnFq4HtwBWZw194vUZvABR43Ct+HXfZ80oReU9C53UiMMaYD8TOoBljxpIfAx8DbhWRj+Butu/E3eD/USAOnJW1zmbgZRH5OW7ojMuAxcDNqtoIoKopEbkWNxTGKhH5pVf3YlwPzh+o6havrorIFbhhNlaKyOAwG+W4YTaeBJYepuM3xhwhLEEzxowZqpoQkfNxQ1R8Fhgcx6wFWAn8OsdqS3Fjjl2HS+S2A19V1R9nbfsJEfko8G3cWbMIroPBVap6T1bdVSKyGLgRuAj4ArDH24eXDsGhGmOOcDYOmjFmXMoYB+0KVb0vv3tjjDEHx+5BM8YYY4zxGUvQjDHGGGN8xhI0Y4wxxhifsXvQjDHGGGN8xs6gGWOMMcb4jCVoxhhjjDE+YwmaMcYYY4zPWIJmjDHGGOMzlqAZY4wxxviMJWjGGGOMMT7z/z+/bdk82rznAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "\n",
    "plt.plot(learning_hist.history['loss'])\n",
    "plt.plot(learning_hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'Valid'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
